"""FastAPI Web UI for Wenning

å®Œå…¨é€æ˜ã€å¯æ§çš„å‰ç«¯å®ç°ï¼Œé›¶é»‘ç›’ã€‚
"""

from fastapi import FastAPI, Query, Depends, HTTPException, Request, UploadFile, File, Form
from fastapi.responses import StreamingResponse, FileResponse, JSONResponse, Response
from fastapi.staticfiles import StaticFiles
from pathlib import Path
import json
import time
import pandas as pd
from typing import Optional, List
from dataclasses import asdict, is_dataclass
from pydantic import BaseModel
from starlette.middleware.sessions import SessionMiddleware

from src.utils.config import get_config
from src.agent.master_agent import MasterAgent
from src.tools.registry import ToolRegistry
from src.tools.atomic.web_search import WebSearchTool
from src.tools.atomic.url_fetch import URLFetchTool
from src.tools.atomic.code_executor import CodeExecutor
from src.tools.atomic.shell_executor import ShellExecutor
from src.tools.atomic.plan import PlanTool
from src.tools.atomic.file_reader import FileReader
from src.tools.atomic.file_list import FileList
from src.tools.atomic.file_editor import FileEditor
from src.tools.atomic.file_writer import FileWriter
from src.tools.atomic.media_ffmpeg import MediaFFmpeg
# é€šç”¨å›¾åƒç”Ÿæˆå·¥å…·
from src.tools.atomic.image_generation import ImageGeneration
# MiniMaxå¤šæ¨¡æ€å·¥å…·
from src.tools.atomic.tts_minimax import TTSMiniMax
from src.tools.atomic.voice_clone_minimax import VoiceCloneMiniMax
# from src.tools.atomic.video_generation_minimax import VideoGenerationMiniMax  # è§†é¢‘ç”Ÿæˆæš‚æ—¶ç¦ç”¨
from src.tools.atomic.music_generation_minimax import MusicGenerationMiniMax
# Promptæ¨¡æ¿æ£€ç´¢å·¥å…·
from src.tools.atomic.prompt_template_tool import PromptTemplateRetriever
# äº‘ç«¯TTSæš‚ä¸å¯ç”¨
# from src.tools.atomic.tts_google import TTSGoogle
# from src.tools.atomic.tts_azure import TTSAzure
from src.utils.logger import get_logger
from src.utils.conversation_manager_v2 import ConversationManagerV2
from src.tools.result import ToolResult
from src.utils.auth import AuthStore
from src.utils.workspace_store import WorkspaceStore
from src.utils.workspace_manager import WorkspaceManager

logger = get_logger(__name__)


def make_json_serializable(obj):
    """é€’å½’åœ°å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
    if isinstance(obj, ToolResult):
        # å°†ToolResultè½¬æ¢ä¸ºdict
        result = asdict(obj)
        # å¤„ç†ErrorTypeæšä¸¾
        if result.get('error_type'):
            result['error_type'] = result['error_type'].value if hasattr(result['error_type'], 'value') else str(result['error_type'])
        return result
    elif isinstance(obj, dict):
        return {k: make_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [make_json_serializable(item) for item in obj]
    elif is_dataclass(obj):
        return asdict(obj)
    elif hasattr(obj, '__dict__'):
        return make_json_serializable(obj.__dict__)
    else:
        return obj


app = FastAPI(title="Wenning")

# å…¨å±€å­˜å‚¨
agents = {}  # {model_name: MasterAgent}
current_conversation = {}  # {model_name: conv_id}

# é…ç½®å’Œå¯¹è¯ç®¡ç†å™¨
config = get_config()
conv_manager = ConversationManagerV2()
auth_store = AuthStore(Path("data/users.json"), allow_register=config.auth_allow_register)
app.add_middleware(SessionMiddleware, secret_key=config.auth_secret)
workspace_store = WorkspaceStore(Path("data/workspace.json"))
workspace_manager = WorkspaceManager(Path(config.output_dir), conv_manager)


def require_user():
    def _dep(request: Request):
        if not config.auth_required:
            return request.session.get('user') or 'anonymous'
        user = request.session.get('user')
        if not user:
            raise HTTPException(status_code=401, detail="æœªç™»å½•")
        return user
    return _dep


class AuthBody(BaseModel):
    username: str
    password: str


def get_or_create_agent(model_name: str = "gpt-5.2") -> MasterAgent:
    """è·å–æˆ–åˆ›å»ºAgentå®ä¾‹"""
    if model_name not in agents:
        # åˆå§‹åŒ–Tool Registry
        tool_registry = ToolRegistry()

        # 1. æ ¸å¿ƒå·¥å…·ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        tool_registry.register_atomic_tool(WebSearchTool(config))
        tool_registry.register_atomic_tool(URLFetchTool(config))
        tool_registry.register_atomic_tool(CodeExecutor(config, conv_manager))

        # 2. ä¸“ç”¨å¤šæ¨¡æ€ç”Ÿæˆå·¥å…·ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
        tool_registry.register_atomic_tool(ImageGeneration(config, conv_manager))  # é€šç”¨å›¾åƒç”Ÿæˆ
        # tool_registry.register_atomic_tool(VideoGenerationMiniMax(config, conv_manager))  # è§†é¢‘ç”Ÿæˆæš‚æ—¶ç¦ç”¨
        tool_registry.register_atomic_tool(MusicGenerationMiniMax(config, conv_manager))
        tool_registry.register_atomic_tool(TTSMiniMax(config, conv_manager))
        tool_registry.register_atomic_tool(VoiceCloneMiniMax(config, conv_manager))  # éŸ³è‰²å…‹éš†

        # 3. é€šç”¨è¾…åŠ©å·¥å…·
        tool_registry.register_atomic_tool(PlanTool(config))
        tool_registry.register_atomic_tool(MediaFFmpeg(config))
        tool_registry.register_atomic_tool(ShellExecutor(config))
        tool_registry.register_atomic_tool(FileReader(config))
        tool_registry.register_atomic_tool(FileList(config))
        tool_registry.register_atomic_tool(FileEditor(config))
        tool_registry.register_atomic_tool(FileWriter(config))
        tool_registry.register_atomic_tool(PromptTemplateRetriever(config))  # Promptæ¨¡æ¿æ£€ç´¢
        # äº‘ç«¯TTSæš‚ä¸æ³¨å†Œï¼ŒæŒ‰éœ€å¼€å¯
        # tool_registry.register_atomic_tool(TTSGoogle(config))
        # tool_registry.register_atomic_tool(TTSAzure(config))

        # åˆ›å»ºAgentï¼ˆä¼ å…¥conv_managerç”¨äºè·¯å¾„è½¬æ¢ï¼‰
        agent = MasterAgent(config, tool_registry, model_name=model_name, conv_manager=conv_manager)
        agents[model_name] = agent
        logger.info(f"åˆ›å»ºæ–°Agent: model={model_name}, tools={len(tool_registry.list_tools())}")

    return agents[model_name]


@app.get("/chat")
async def chat(
    message: str = Query(..., description="ç”¨æˆ·æ¶ˆæ¯"),
    model: str = Query("gpt-5.2", description="æ¨¡å‹åç§°"),
    conversation_id: str = Query(..., description="å¯¹è¯ID"),
    client_msg_id: Optional[str] = Query(None, description="å‰ç«¯å¹‚ç­‰ID"),
    user: str = Depends(require_user())
):
    """èŠå¤©æ¥å£ - Server-Sent Eventsæµå¼å“åº”"""

    def generate():
        try:
            # è·å–å¯¹è¯å†å²å¹¶è®¾ç½®åˆ°Agent
            conv = conv_manager.get_conversation(conversation_id, username=user)
            if not conv:
                raise ValueError(f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}")

            # æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼šè‹¥å‰ç«¯ä¼ å…¥ä¸ä¼šè¯ä¿å­˜çš„æ¨¡å‹ä¸åŒï¼Œåˆ™æ›´æ–°ä¼šè¯ç»‘å®šæ¨¡å‹
            saved_model = conv.get("model", "gpt-5.2")
            effective_model = (model or saved_model) if model else saved_model
            if effective_model and effective_model != saved_model:
                try:
                    conv_manager.set_conversation_model(conversation_id, effective_model, username=user)
                    logger.info(f"ä¼šè¯{conversation_id}åˆ‡æ¢æ¨¡å‹: {saved_model} -> {effective_model}")
                except Exception as _:
                    # å¤±è´¥åˆ™é€€å›åŸæ¨¡å‹
                    effective_model = saved_model
            agent = get_or_create_agent(effective_model)
            logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: model={effective_model}, conv_id={conversation_id}, message={message[:50]}...")

            conversation_history = conv.get("messages", [])

            # è¯¦ç»†æ—¥å¿—ï¼šæ£€æŸ¥ä»æ•°æ®åº“åŠ è½½çš„å†å²
            logger.info(f"=== å¯¹è¯å†å²åŠ è½½è°ƒè¯• ===")
            logger.info(f"ä»æ•°æ®åº“åŠ è½½çš„æ¶ˆæ¯æ•°: {len(conversation_history)}")
            if conversation_history:
                logger.info(f"æœ€å5æ¡æ¶ˆæ¯roles: {[msg.get('role') for msg in conversation_history[-5:]]}")
                for i, msg in enumerate(conversation_history[-3:], start=max(0, len(conversation_history)-3)):
                    role = msg.get('role')
                    content_preview = msg.get('content', '')[:100] if msg.get('content') else '(empty)'
                    logger.info(f"  [{i}] {role}: {content_preview}")
            else:
                logger.info("âš ï¸  conversation_historyä¸ºç©ºï¼")

            # æ¯æ¬¡éƒ½ä»æ•°æ®åº“åŠ è½½æœ€æ–°çš„å®Œæ•´å¯¹è¯å†å²ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡å®Œæ•´æ€§
            agent.conversation_history = list(conversation_history)
            agent.current_conversation_id = conversation_id
            logger.info(f"å·²è®¾ç½®Agent.conversation_history: {len(agent.conversation_history)}æ¡æ¶ˆæ¯")

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¸¦å¹‚ç­‰IDï¼‰
            conv_manager.add_message(conversation_id, "user", message, username=user, client_msg_id=client_msg_id, status="completed")

            # å®šä¹‰æ¶ˆæ¯ä¿å­˜å›è°ƒå‡½æ•°
            def save_message_callback(msg: dict):
                """æ¯å½“Agentäº§ç”Ÿæ–°æ¶ˆæ¯æ—¶è°ƒç”¨æ­¤å›è°ƒä¿å­˜åˆ°æ•°æ®åº“"""
                role = msg.get("role")
                content = msg.get("content", "")

                if role == "assistant":
                    tool_calls = msg.get("tool_calls")
                    conv_manager.add_message(
                        conversation_id,
                        role="assistant",
                        content=content,
                        tool_calls=tool_calls,
                        username=user,
                        status="completed"
                    )
                elif role == "tool":
                    tool_call_id = msg.get("tool_call_id")
                    name = msg.get("name")
                    conv_manager.add_message(
                        conversation_id,
                        role="tool",
                        content=content,
                        tool_call_id=tool_call_id,
                        name=name,
                        username=user,
                        status="completed"
                    )

            # è®¾ç½®å›è°ƒå‡½æ•°åˆ°Agent
            agent.message_callback = save_message_callback

            # æµå¼å¤„ç†
            assistant_response = None
            all_generated_files = []  # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
            # æ‰§è¡Œå‰å¿«ç…§ä¸å¼€å§‹æ—¶é—´ï¼Œç”¨äºå…œåº•è¡¥é½è¦†ç›–å†™æˆ–é—æ¼æ–‡ä»¶
            start_ts = time.time()
            # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
            output_dir_name = conv_manager.get_output_dir_name(conversation_id)
            conv_dir = Path("outputs") / output_dir_name
            try:
                pre_files = {p.name for p in conv_dir.iterdir() if p.is_file()}
            except Exception:
                pre_files = set()

            for update in agent.process_with_progress(message):
                # æ”¶é›†ç”Ÿæˆçš„æ–‡ä»¶
                if update.get("type") == "files_generated":
                    new_files = update.get("files", []) or []
                    all_generated_files.extend(new_files)

                # è½¬å‘ç»™å‰ç«¯(å¤„ç†ToolResultç­‰ä¸å¯åºåˆ—åŒ–å¯¹è±¡)
                serializable_update = make_json_serializable(update)
                yield f"data: {json.dumps(serializable_update, ensure_ascii=False)}\n\n"

            # å…œåº•ï¼šæ›´æ–°æœ€åä¸€æ¡assistantæ¶ˆæ¯çš„generated_files
            # æ‰«ææ‰§è¡ŒæœŸé—´æ–°å¢/è¦†ç›–çš„æ–‡ä»¶
            try:
                unique_files = list(dict.fromkeys(all_generated_files)) if all_generated_files else []
            except Exception:
                unique_files = all_generated_files or []

            try:
                post_paths = [p for p in conv_dir.iterdir() if p.is_file()]
                post_files = {p.name for p in post_paths}
            except Exception:
                post_paths = []
                post_files = set()
            new_set = post_files - pre_files
            try:
                changed = [p.name for p in post_paths if p.stat().st_mtime >= (start_ts - 0.2)]
            except Exception:
                changed = []
            merged = list(dict.fromkeys((unique_files or []) + sorted(list(new_set)) + changed))

            # æ›´æ–°æœ€åä¸€æ¡assistantæ¶ˆæ¯çš„generated_files
            if merged:
                try:
                    conv = conv_manager.get_conversation(conversation_id, username=user)
                    if conv and conv.get("messages"):
                        # æ‰¾åˆ°æœ€åä¸€æ¡assistantæ¶ˆæ¯
                        for i in range(len(conv["messages"]) - 1, -1, -1):
                            if conv["messages"][i].get("role") == "assistant":
                                last_assistant_id = conv["messages"][i].get("id")
                                if last_assistant_id:
                                    conv_manager.update_message(
                                        conversation_id,
                                        message_id=last_assistant_id,
                                        generated_files_delta=merged,
                                        username=user
                                    )
                                    logger.info(f"å·²æ›´æ–°æœ€åassistantæ¶ˆæ¯çš„generated_files: {merged}")
                                break
                except Exception as e:
                    logger.warning(f"æ›´æ–°generated_fileså¤±è´¥: {e}")

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šå‘é€files_generatedäº‹ä»¶é€šçŸ¥å‰ç«¯åŠ è½½é¢„è§ˆ
                # è¿™ä¸ªå…œåº•æœºåˆ¶ä¼šæ•è·é‚£äº›å·¥å…·æ²¡æœ‰æ­£ç¡®æŠ¥å‘Šçš„æ–‡ä»¶ï¼ˆå¦‚è¦†ç›–å†™ã€å»¶è¿Ÿç”Ÿæˆç­‰ï¼‰
                try:
                    if merged:
                        files_event = {
                            "type": "files_generated",
                            "files": merged,
                            "iter": None  # å…œåº•æ‰«æï¼Œä¸å±äºç‰¹å®šiter
                        }
                        yield f"data: {json.dumps(files_event, ensure_ascii=False)}\n\n"
                        logger.info(f"å·²å‘é€å…œåº•files_generatedäº‹ä»¶: {merged}")
                except Exception as e:
                    logger.warning(f"å‘é€files_generatedäº‹ä»¶å¤±è´¥: {e}")

            # å‘é€ç»“æŸæ ‡è®°
            yield "data: [DONE]\n\n"

        except Exception as e:
            logger.error(f"èŠå¤©å¤„ç†å¼‚å¸¸: {str(e)}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")

            # å‘é€é”™è¯¯ä¿¡æ¯
            error_update = {
                "type": "final",
                "result": {
                    "status": "failed",
                    "error": str(e)
                }
            }
            yield f"data: {json.dumps(error_update, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

@app.get("/outputs/list/{conversation_id}")
async def list_outputs_alt(conversation_id: str, user: str = Depends(require_user())):
    """åˆ—å‡ºä¼šè¯ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼ˆå¤‡ç”¨è·¯ç”±ï¼‰"""
    return await list_outputs(conversation_id, user)


@app.get("/outputs/{conversation_id}/{filename}")
async def get_file_scoped(conversation_id: str, filename: str, user: str = Depends(require_user())):
    """å¯¹è¯éš”ç¦»çš„æ–‡ä»¶ä¸‹è½½æ¥å£ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼šä»…ä¼šè¯ç›®å½•ï¼Œä¸å›é€€æ ¹ç›®å½•ï¼‰"""
    # æƒé™æ ¡éªŒï¼šä»…å…è®¸è®¿é—®è‡ªå·±çš„ä¼šè¯
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})
    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    file_path = Path("outputs") / output_dir_name / filename

    if not file_path.exists():
        return JSONResponse(status_code=404, content={"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"})

    suffix = file_path.suffix.lower()
    if suffix == ".png":
        media_type = "image/png"
    elif suffix in (".jpg", ".jpeg"):
        media_type = "image/jpeg"
    elif suffix == ".svg":
        media_type = "image/svg+xml"
    elif suffix == ".gif":
        media_type = "image/gif"
    elif suffix == ".webp":
        media_type = "image/webp"
    elif suffix == ".avif":
        media_type = "image/avif"
    elif suffix in (".mp3", ".mpeg"):
        media_type = "audio/mpeg"
    elif suffix == ".wav":
        media_type = "audio/wav"
    elif suffix == ".m4a":
        media_type = "audio/mp4"
    elif suffix == ".aac":
        media_type = "audio/aac"
    elif suffix == ".ogg":
        media_type = "audio/ogg"
    elif suffix == ".flac":
        media_type = "audio/flac"
    elif suffix == ".mp4":
        media_type = "video/mp4"
    elif suffix == ".webm":
        media_type = "video/webm"
    elif suffix == ".mov":
        media_type = "video/quicktime"
    elif suffix == ".xlsx":
        media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    elif suffix == ".pdf":
        media_type = "application/pdf"
    elif suffix == ".csv":
        media_type = "text/csv; charset=utf-8"
    elif suffix == ".jsonl":
        media_type = "application/jsonl; charset=utf-8"
    elif suffix == ".json":
        media_type = "application/json; charset=utf-8"
    elif suffix == ".txt":
        media_type = "text/plain; charset=utf-8"
    elif suffix in (".yaml", ".yml"):
        media_type = "text/yaml; charset=utf-8"
    elif suffix == ".xml":
        media_type = "application/xml; charset=utf-8"
    elif suffix == ".md":
        media_type = "text/markdown; charset=utf-8"
    elif suffix == ".html":
        media_type = "text/html; charset=utf-8"
    elif suffix == ".docx":
        media_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    elif suffix == ".pptx":
        media_type = "application/vnd.openxmlformats-officedocument.presentationml.presentation"
    else:
        media_type = "application/octet-stream"

    headers = {"X-File-Scope": "conversation"}
    # ä¸ºå¯å†…è”é¢„è§ˆçš„ç±»å‹å»æ‰ filename, é¿å… Content-Disposition: attachment å¯¼è‡´æµè§ˆå™¨ä¸å†…è”æ¸²æŸ“ï¼ˆSVG å°¤å…¶å¦‚æ­¤ï¼‰
    inline_types = {
        ".html", ".txt", ".md", ".json", ".jsonl", ".yaml", ".yml", ".xml",
        ".png", ".jpg", ".jpeg", ".svg", ".gif", ".webp", ".avif",
        ".mp3", ".wav", ".m4a", ".aac", ".ogg", ".flac",
        ".mp4", ".webm", ".mov",
        ".pdf"
    }
    if suffix in inline_types:
        return FileResponse(path=str(file_path), media_type=media_type, headers=headers)
    return FileResponse(path=str(file_path), filename=filename, media_type=media_type, headers=headers)


@app.head("/outputs/{conversation_id}/{filename}")
async def head_file_scoped(conversation_id: str, filename: str, user: str = Depends(require_user())):
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})
    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    path = Path("outputs") / output_dir_name / filename

    if not path.exists():
        return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})
    suffix = path.suffix.lower()
    if suffix == ".png":
        media_type = "image/png"
    elif suffix in (".jpg", ".jpeg"):
        media_type = "image/jpeg"
    elif suffix in (".mp3", ".mpeg"):
        media_type = "audio/mpeg"
    elif suffix == ".wav":
        media_type = "audio/wav"
    elif suffix == ".m4a":
        media_type = "audio/mp4"
    elif suffix == ".aac":
        media_type = "audio/aac"
    elif suffix == ".ogg":
        media_type = "audio/ogg"
    elif suffix == ".flac":
        media_type = "audio/flac"
    elif suffix == ".mp4":
        media_type = "video/mp4"
    elif suffix == ".webm":
        media_type = "video/webm"
    elif suffix == ".mov":
        media_type = "video/quicktime"
    elif suffix == ".xlsx":
        media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    elif suffix == ".pdf":
        media_type = "application/pdf"
    elif suffix == ".csv":
        media_type = "text/csv; charset=utf-8"
    elif suffix == ".jsonl":
        media_type = "application/jsonl; charset=utf-8"
    elif suffix == ".json":
        media_type = "application/json; charset=utf-8"
    elif suffix == ".txt":
        media_type = "text/plain; charset=utf-8"
    elif suffix == ".md":
        media_type = "text/markdown; charset=utf-8"
    elif suffix == ".html":
        media_type = "text/html; charset=utf-8"
    elif suffix == ".docx":
        media_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    elif suffix == ".pptx":
        media_type = "application/vnd.openxmlformats-officedocument.presentationml.presentation"
    else:
        media_type = "application/octet-stream"

    return JSONResponse(status_code=200, content=None, headers={"Content-Type": media_type, "X-File-Scope": "conversation"})


@app.post("/upload/{conversation_id}")
async def upload_files(
    conversation_id: str,
    files: List[UploadFile] = File(...),
    add_to_workspace: bool = Form(False),
    user: str = Depends(require_user()),
):
    """ä¸Šä¼ æ–‡ä»¶åˆ°ä¼šè¯éš”ç¦»ç›®å½•(outputs/{conversation_id}/)ã€‚

    - ä»…ä¿å­˜æ–‡ä»¶åï¼Œä¸å…è®¸è·¯å¾„ç©¿è¶Š
    - åŒåæ–‡ä»¶è‡ªåŠ¨è¿½åŠ  _1/_2 åç¼€é¿å…è¦†ç›–
    - å¯é€‰å†™å…¥Workspaceåˆ—è¡¨
    """
    # æƒé™æ ¡éªŒ
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})

    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    conv_dir = Path("outputs") / output_dir_name
    conv_dir.mkdir(parents=True, exist_ok=True)

    saved: List[str] = []
    for uf in (files or []):
        try:
            raw_name = (uf.filename or "upload.bin").strip()
            # ä»…ä¿ç•™æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„ç©¿è¶Š
            safe_name = Path(raw_name).name
            if not safe_name or safe_name in (".", ".."):
                import time as _t
                safe_name = f"upload_{int(_t.time()*1000)}.bin"

            target = conv_dir / safe_name
            if target.exists():
                # åŒåå»é‡: name -> name_1.ext -> name_2.ext
                stem, suf = target.stem, target.suffix
                i = 1
                while target.exists():
                    target = conv_dir / f"{stem}_{i}{suf}"
                    i += 1

            # æµå¼å†™å…¥ï¼Œé¿å…ä¸€æ¬¡æ€§è¯»å¤§æ–‡ä»¶
            with target.open("wb") as w:
                while True:
                    chunk = await uf.read(1024 * 1024)
                    if not chunk:
                        break
                    w.write(chunk)
            await uf.close()

            saved.append(target.name)

            # æ£€æµ‹æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶ï¼Œè‡ªåŠ¨æ·»åŠ åˆ°pending_images
            image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'}
            if target.suffix.lower() in image_extensions:
                # æ·»åŠ åˆ°pending_imagesï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼šoutput_dir_name/filenameï¼‰
                relative_path = f"{output_dir_name}/{target.name}"
                conv_manager.add_pending_image(conversation_id, relative_path, username=user)
                logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œå·²æ·»åŠ åˆ°pending_images: {relative_path}")

            # å¯é€‰åŠ å…¥Workspaceåˆ—è¡¨
            try:
                if add_to_workspace:
                    workspace_store.add_file(user, conversation_id, target.name)
            except Exception as e:
                logger.warning(f"workspace add failed: {e}")

        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {getattr(uf, 'filename', 'unknown')} error={e}")
            # ä¸ä¸­æ–­å…¶ä½™æ–‡ä»¶
            continue

    return JSONResponse(content={"success": True, "files": saved})


@app.delete("/upload/{conversation_id}/{filename}")
async def delete_file(
    conversation_id: str,
    filename: str,
    user: str = Depends(require_user()),
):
    """åˆ é™¤ä¼šè¯ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œå¹¶ä»Workspaceç§»é™¤è¯¥å¼•ç”¨ã€‚

    å®‰å…¨æªæ–½ï¼š
    - ä»…å…è®¸åˆ é™¤ outputs/{conversation_id} ä¸‹çš„æ–‡ä»¶
    - æ‹’ç»è·¯å¾„ç©¿è¶Šï¼ˆåªæ¥å—çº¯æ–‡ä»¶åï¼‰
    """
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})

    # ä»…æ–‡ä»¶å
    p = Path(filename)
    if p.is_absolute() or p.name != filename or filename in ("", ".", ".."):
        return JSONResponse(status_code=400, content={"error": "éæ³•æ–‡ä»¶å"})

    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    path = Path("outputs") / output_dir_name / filename
    if not path.exists() or not path.is_file():
        return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})

    try:
        path.unlink()
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {path} error={e}")
        return JSONResponse(status_code=500, content={"error": "åˆ é™¤å¤±è´¥"})

    # åŒæ­¥ç§»é™¤Workspaceå¼•ç”¨ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
    try:
        workspace_store.remove_file(user, conversation_id, filename)
    except Exception as e:
        logger.warning(f"workspace remove failed: {e}")

    return JSONResponse(content={"success": True})


# ===== Range streaming (audio/video friendly) =====
def _guess_media_type_by_suffix(suffix: str) -> str:
    s = suffix.lower()
    if s == ".png":
        return "image/png"
    if s in (".jpg", ".jpeg"):
        return "image/jpeg"
    if s == ".svg":
        return "image/svg+xml"
    if s == ".gif":
        return "image/gif"
    if s == ".webp":
        return "image/webp"
    if s == ".avif":
        return "image/avif"
    if s in (".mp3", ".mpeg"):
        return "audio/mpeg"
    if s == ".wav":
        return "audio/wav"
    if s == ".m4a":
        return "audio/mp4"
    if s == ".aac":
        return "audio/aac"
    if s == ".ogg":
        return "audio/ogg"
    if s == ".flac":
        return "audio/flac"
    if s == ".mp4":
        return "video/mp4"
    if s == ".webm":
        return "video/webm"
    if s == ".mov":
        return "video/quicktime"
    if s == ".xlsx":
        return "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    if s == ".html":
        return "text/html; charset=utf-8"
    return "application/octet-stream"


def _iter_file_range(path: Path, start: int, end: int, chunk_size: int = 1024 * 1024):
    with open(path, 'rb') as f:
        f.seek(start)
        remaining = end - start + 1
        while remaining > 0:
            read_len = min(chunk_size, remaining)
            data = f.read(read_len)
            if not data:
                break
            yield data
            remaining -= len(data)


@app.get("/stream/{conversation_id}/{filename}")
async def stream_scoped(conversation_id: str, filename: str, request: Request, user: str = Depends(require_user())):
    # æƒé™æ ¡éªŒ
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})

    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    file_path = Path("outputs") / output_dir_name / filename
    if not file_path.exists() or not file_path.is_file():
        return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})

    file_size = file_path.stat().st_size
    range_header = request.headers.get('range')
    media_type = _guess_media_type_by_suffix(file_path.suffix)
    headers = {"Accept-Ranges": "bytes"}

    if range_header:
        # e.g. "bytes=start-end"
        try:
            units, _, rng = range_header.partition('=')
            if units.strip().lower() != 'bytes':
                raise ValueError
            start_str, _, end_str = rng.partition('-')
            start = int(start_str) if start_str else 0
            end = int(end_str) if end_str else file_size - 1
            start = max(0, start)
            end = min(file_size - 1, end)
            if start > end:
                start, end = 0, file_size - 1
        except Exception:
            start, end = 0, file_size - 1

        content_length = end - start + 1
        headers.update({
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Content-Length": str(content_length)
        })
        return StreamingResponse(_iter_file_range(file_path, start, end), status_code=206, media_type=media_type, headers=headers)

    # No range â†’ full content
    headers["Content-Length"] = str(file_size)
    return StreamingResponse(_iter_file_range(file_path, 0, file_size - 1), media_type=media_type, headers=headers)


@app.get("/stream/{filename}")
async def stream_root(filename: str, request: Request):
    file_path = Path("outputs") / filename
    if not file_path.exists() or not file_path.is_file():
        return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨"})
    file_size = file_path.stat().st_size
    range_header = request.headers.get('range')
    media_type = _guess_media_type_by_suffix(file_path.suffix)
    headers = {"Accept-Ranges": "bytes"}
    if range_header:
        try:
            units, _, rng = range_header.partition('=')
            if units.strip().lower() != 'bytes':
                raise ValueError
            start_str, _, end_str = rng.partition('-')
            start = int(start_str) if start_str else 0
            end = int(end_str) if end_str else file_size - 1
            start = max(0, start)
            end = min(file_size - 1, end)
            if start > end:
                start, end = 0, file_size - 1
        except Exception:
            start, end = 0, file_size - 1

        content_length = end - start + 1
        headers.update({
            "Content-Range": f"bytes {start}-{end}/{file_size}",
            "Content-Length": str(content_length)
        })
        return StreamingResponse(_iter_file_range(file_path, start, end), status_code=206, media_type=media_type, headers=headers)

    headers["Content-Length"] = str(file_size)
    return StreamingResponse(_iter_file_range(file_path, 0, file_size - 1), media_type=media_type, headers=headers)


@app.get("/outputs/{conversation_id}/list")
async def list_outputs(conversation_id: str, user: str = Depends(require_user())):
    """åˆ—å‡ºä¼šè¯ç›®å½•ä¸‹çš„æ–‡ä»¶åï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´å€’åºï¼‰ï¼Œä»…è¿”å›æ–‡ä»¶åã€‚"""
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})
    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    conv_dir = Path("outputs") / output_dir_name
    if not conv_dir.exists():
        return JSONResponse(content={"files": []})
    try:
        items = []
        for p in conv_dir.iterdir():
            if p.is_file():
                try:
                    m = p.stat().st_mtime
                except Exception:
                    m = 0
                items.append((m, p.name))
        items.sort(reverse=True)
        return JSONResponse(content={"files": [n for _, n in items]})
    except Exception as e:
        logger.error(f"åˆ—å‡ºä¼šè¯æ–‡ä»¶å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "list failed"})


@app.get("/preview/excel/{filename}")
async def preview_excel(
    filename: str,
    max_rows: int = Query(20, description="é¢„è§ˆæœ€å¤§è¡Œæ•°")
):
    """Excelæ–‡ä»¶é¢„è§ˆæ¥å£ï¼ˆæ ¹outputsç›®å½• - å…¼å®¹æ—§é“¾æ¥ï¼‰"""
    file_path = Path("outputs") / filename

    if not file_path.exists():
        return JSONResponse(
            status_code=404,
            content={"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
        )

    try:
        df = pd.read_excel(file_path, nrows=max_rows)
        html = df.to_html(index=False, classes='excel-table', border=0, escape=False)
        total_rows = len(pd.read_excel(file_path))
        return JSONResponse(content={
            "html": html,
            "preview_rows": len(df),
            "total_rows": total_rows,
            "truncated": total_rows > max_rows
        })
    except Exception as e:
        logger.error(f"Excelé¢„è§ˆå¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": f"é¢„è§ˆå¤±è´¥: {str(e)}"})


@app.get("/preview/excel/{conversation_id}/{filename}")
async def preview_excel_scoped(
    conversation_id: str,
    filename: str,
    max_rows: int = Query(20, description="é¢„è§ˆæœ€å¤§è¡Œæ•°"),
    user: str = Depends(require_user())
):
    """Excelæ–‡ä»¶é¢„è§ˆæ¥å£ï¼ˆä¼šè¯éš”ç¦»ç›®å½•ï¼‰"""
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})
    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    file_path = Path("outputs") / output_dir_name / filename

    if not file_path.exists():
        return JSONResponse(
            status_code=404,
            content={"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
        )

    try:
        df = pd.read_excel(file_path, nrows=max_rows)
        html = df.to_html(index=False, classes='excel-table', border=0, escape=False)
        total_rows = len(pd.read_excel(file_path))
        return JSONResponse(content={
            "html": html,
            "preview_rows": len(df),
            "total_rows": total_rows,
            "truncated": total_rows > max_rows
        })
    except Exception as e:
        logger.error(f"[scoped] Excelé¢„è§ˆå¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": f"é¢„è§ˆå¤±è´¥: {str(e)}"})


@app.get("/preview/word/{conversation_id}/{filename}")
async def preview_word(
    conversation_id: str,
    filename: str,
    user: str = Depends(require_user())
):
    """Wordæ–‡ä»¶é¢„è§ˆæ¥å£ï¼ˆ.doc/.docxï¼‰- ä½¿ç”¨mammothè½¬æ¢ä¸ºHTML"""
    conv = conv_manager.get_conversation(conversation_id, username=user)
    if not conv:
        logger.warning(f"Wordé¢„è§ˆå¤±è´¥: ä¼šè¯ {conversation_id} ä¸å­˜åœ¨æˆ–ç”¨æˆ· {user} æ— æƒé™")
        return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})

    # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
    output_dir_name = conv_manager.get_output_dir_name(conversation_id)
    file_path = Path("outputs") / output_dir_name / filename

    logger.info(f"Wordé¢„è§ˆ: conversation_id={conversation_id}, output_dir={output_dir_name}, file_path={file_path}")

    if not file_path.exists():
        logger.warning(f"Wordé¢„è§ˆå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return JSONResponse(
            status_code=404,
            content={"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
        )

    try:
        import mammoth

        # ä½¿ç”¨mammothè½¬æ¢Wordä¸ºHTML
        with open(file_path, "rb") as docx_file:
            result = mammoth.convert_to_html(docx_file)
            html_content = result.value  # ç”Ÿæˆçš„HTML
            messages = result.messages  # è½¬æ¢è­¦å‘Š/é”™è¯¯

        # è®°å½•è½¬æ¢è­¦å‘Š
        if messages:
            for msg in messages:
                logger.warning(f"Wordè½¬æ¢è­¦å‘Š: {msg}")

        return JSONResponse(content={
            "html": html_content,
            "warnings": [str(msg) for msg in messages] if messages else []
        })

    except ImportError:
        logger.error("mammothåº“æœªå®‰è£…ï¼Œæ— æ³•é¢„è§ˆWordæ–‡æ¡£")
        return JSONResponse(
            status_code=500,
            content={"error": "æœåŠ¡å™¨ç¼ºå°‘Wordé¢„è§ˆæ”¯æŒï¼Œè¯·è”ç³»ç®¡ç†å‘˜"}
        )
    except Exception as e:
        logger.error(f"Wordé¢„è§ˆå¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": f"é¢„è§ˆå¤±è´¥: {str(e)}"})


@app.get("/preview/word/{filename}")
async def preview_word_legacy(filename: str):
    """Wordæ–‡ä»¶é¢„è§ˆæ¥å£ï¼ˆæ ¹outputsç›®å½• - å…¼å®¹æ—§é“¾æ¥ï¼‰"""
    file_path = Path("outputs") / filename

    if not file_path.exists():
        return JSONResponse(
            status_code=404,
            content={"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
        )

    try:
        import mammoth

        # ä½¿ç”¨mammothè½¬æ¢Wordä¸ºHTML
        with open(file_path, "rb") as docx_file:
            result = mammoth.convert_to_html(docx_file)
            html_content = result.value
            messages = result.messages

        # è®°å½•è½¬æ¢è­¦å‘Š
        if messages:
            for msg in messages:
                logger.warning(f"Wordè½¬æ¢è­¦å‘Š: {msg}")

        return JSONResponse(content={
            "html": html_content,
            "warnings": [str(msg) for msg in messages] if messages else []
        })

    except ImportError:
        logger.error("mammothåº“æœªå®‰è£…ï¼Œæ— æ³•é¢„è§ˆWordæ–‡æ¡£")
        return JSONResponse(
            status_code=500,
            content={"error": "æœåŠ¡å™¨ç¼ºå°‘Wordé¢„è§ˆæ”¯æŒï¼Œè¯·è”ç³»ç®¡ç†å‘˜"}
        )
    except Exception as e:
        logger.error(f"Wordé¢„è§ˆå¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": f"é¢„è§ˆå¤±è´¥: {str(e)}"})


@app.get("/preview/showcase/word/{filename}")
async def preview_showcase_word(filename: str):
    """Showcase Wordæ–‡ä»¶é¢„è§ˆæ¥å£"""
    file_path = Path("static/showcase") / filename

    if not file_path.exists():
        return JSONResponse(
            status_code=404,
            content={"error": f"Showcaseæ–‡ä»¶ä¸å­˜åœ¨: {filename}"}
        )

    try:
        import mammoth

        # ä½¿ç”¨mammothè½¬æ¢Wordä¸ºHTML
        with open(file_path, "rb") as docx_file:
            result = mammoth.convert_to_html(docx_file)
            html_content = result.value
            messages = result.messages

        # è®°å½•è½¬æ¢è­¦å‘Š
        if messages:
            for msg in messages:
                logger.warning(f"Showcase Wordè½¬æ¢è­¦å‘Š: {msg}")

        return JSONResponse(content={
            "html": html_content,
            "warnings": [str(msg) for msg in messages] if messages else []
        })

    except ImportError:
        logger.error("mammothåº“æœªå®‰è£…ï¼Œæ— æ³•é¢„è§ˆWordæ–‡æ¡£")
        return JSONResponse(
            status_code=500,
            content={"error": "æœåŠ¡å™¨ç¼ºå°‘Wordé¢„è§ˆæ”¯æŒï¼Œè¯·è”ç³»ç®¡ç†å‘˜"}
        )
    except Exception as e:
        logger.error(f"Showcase Wordé¢„è§ˆå¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": f"é¢„è§ˆå¤±è´¥: {str(e)}"})


@app.get("/models")
async def list_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models = [
        {"name": "gpt-5.2", "display_name": "OpenAI GPT-5.2", "default": True},
        {"name": "gpt-5", "display_name": "OpenAI GPT-5", "default": False},
        {"name": "ernie-5.0-thinking-preview", "display_name": "ç™¾åº¦ EB5 æ€è€ƒæ¨¡å‹", "default": False},
        {"name": "glm-4.5", "display_name": "æ™ºè°±GLM-4.5", "default": False},
        {"name": "doubao-seed-1-6-thinking-250615", "display_name": "è±†åŒ…Thinkingæ¨¡å‹", "default": False},
        {"name": "gemini-2.5-pro", "display_name": "Google Gemini 2.5 Pro", "default": False},
        {"name": "gemini-3-pro-preview", "display_name": "Google Gemini 3 Pro (Preview)", "default": False},
        {"name": "claude-sonnet-4-5-20250929", "display_name": "Anthropic Claude Sonnet 4.5 (2025-09-29)", "default": False},
    ]
    return JSONResponse(content={"models": models})


@app.get("/conversations")
async def list_conversations(model: str = Query(None, description="æ¨¡å‹åç§°ç­›é€‰"), user: str = Depends(require_user())):
    """åˆ—å‡ºæ‰€æœ‰å¯¹è¯"""
    try:
        convs = conv_manager.list_conversations(model, username=user)
        return JSONResponse(content={"conversations": convs})
    except Exception as e:
        logger.error(f"åˆ—å‡ºå¯¹è¯å¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


class CreateConversationBody(BaseModel):
    model: str = "gpt-5.2"

@app.post("/conversations")
async def create_conversation(body: CreateConversationBody = None, user: str = Depends(require_user())):
    """åˆ›å»ºæ–°å¯¹è¯"""
    try:
        # å…¼å®¹ä¸¤ç§æ–¹å¼ï¼šå¦‚æœæœ‰bodyåˆ™ä½¿ç”¨body.modelï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
        model = body.model if body else "gpt-5.2"
        conv_id = conv_manager.create_conversation(model, username=user)
        logger.info(f"åˆ›å»ºæ–°å¯¹è¯: conv_id={conv_id}, model={model}, user={user}")
        return JSONResponse(content={"conversation_id": conv_id})
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯¹è¯å¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str, user: str = Depends(require_user())):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    try:
        conv = conv_manager.get_conversation(conversation_id, username=user)
        if not conv:
            return JSONResponse(status_code=404, content={"error": "å¯¹è¯ä¸å­˜åœ¨"})

        # æ·»åŠ output_dirå­—æ®µåˆ°è¿”å›æ•°æ®ï¼ˆå‰ç«¯éœ€è¦ç”¨å®ƒæ„é€ æ–‡ä»¶è·¯å¾„ï¼‰
        conv["output_dir"] = conv_manager.get_output_dir_name(conversation_id)

        # è®¡ç®—å½“å‰å¯¹è¯çš„contextä½¿ç”¨æƒ…å†µ
        if conv.get("messages") and len(conv["messages"]) > 0:
            try:
                model_name = conv.get("model", "gpt-5.2")
                agent = get_or_create_agent(model_name)
                context_stats = agent.context_manager.calculate_usage(conv["messages"])
                conv["context_stats"] = context_stats
            except Exception as e:
                logger.warning(f"è®¡ç®—contextç»Ÿè®¡å¤±è´¥: {str(e)}")
                # å³ä½¿è®¡ç®—å¤±è´¥ä¹Ÿç»§ç»­è¿”å›å¯¹è¯

        return JSONResponse(content=conv)
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯å¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


class UpdateConversationModelBody(BaseModel):
    model: str


@app.patch("/conversations/{conversation_id}/model")
async def update_conversation_model(
    conversation_id: str,
    body: UpdateConversationModelBody,
    user: str = Depends(require_user())
):
    """æ›´æ–°å¯¹è¯ä½¿ç”¨çš„æ¨¡å‹"""
    try:
        success = conv_manager.update_model(conversation_id, body.model, username=user)
        if not success:
            return JSONResponse(
                status_code=404,
                content={"error": "å¯¹è¯ä¸å­˜åœ¨æˆ–æ— æƒé™"}
            )
        return JSONResponse(content={"success": True, "model": body.model})
    except Exception as e:
        logger.error(f"æ›´æ–°å¯¹è¯æ¨¡å‹å¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str, user: str = Depends(require_user())):
    """åˆ é™¤å¯¹è¯"""
    try:
        conv_manager.delete_conversation(conversation_id, username=user)
        logger.info(f"åˆ é™¤å¯¹è¯: conv_id={conversation_id}")
        return JSONResponse(content={"success": True})
    except Exception as e:
        logger.error(f"åˆ é™¤å¯¹è¯å¤±è´¥: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")


@app.get("/")
async def index():
    """é¦–é¡µ"""
    index_file = Path("static/index.html")
    if not index_file.exists():
        return JSONResponse(
            status_code=404,
            content={"error": "å‰ç«¯æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆåˆ›å»º static/index.html"}
        )
    return FileResponse("static/index.html")


# ========== Auth APIs ==========

@app.post("/auth/register")
async def auth_register(body: AuthBody):
    if not config.auth_allow_register:
        return JSONResponse(status_code=403, content={"error": "æ³¨å†Œè¢«ç¦ç”¨"})
    try:
        auth_store.register(body.username, body.password)
        return JSONResponse(content={"success": True})
    except ValueError as e:
        # ä¸šåŠ¡æ ¡éªŒé”™è¯¯ï¼ˆå¦‚ç”¨æˆ·å·²å­˜åœ¨ï¼‰
        return JSONResponse(status_code=400, content={"error": str(e)})
    except Exception as e:
        logger.error(f"æ³¨å†Œå¤±è´¥: {e}")
        return JSONResponse(status_code=400, content={"error": "æ³¨å†Œå¤±è´¥"})


@app.post("/auth/login")
async def auth_login(body: AuthBody, request: Request):
    if not auth_store.verify(body.username, body.password):
        return JSONResponse(status_code=401, content={"error": "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"})
    request.session['user'] = body.username
    return JSONResponse(content={"success": True, "user": body.username})


@app.post("/auth/logout")
async def auth_logout(request: Request):
    request.session.pop('user', None)
    return JSONResponse(content={"success": True})


@app.get("/auth/me")
async def auth_me(request: Request):
    user = request.session.get('user')
    if config.auth_required and not user:
        return JSONResponse(status_code=401, content={"error": "æœªç™»å½•"})
    return JSONResponse(content={
        "user": user or None,
        "logged_in": bool(user),
        "auth_required": config.auth_required,
        "allow_register": config.auth_allow_register,
    })


@app.get("/auth/config")
async def auth_config():
    """å…¬å¼€çš„è®¤è¯é…ç½®ï¼Œä¾¿äºå‰ç«¯åœ¨æœªç™»å½•æ—¶åšUIè°ƒæ•´"""
    return JSONResponse(content={
        "auth_required": config.auth_required,
        "allow_register": config.auth_allow_register,
    })


# ========== Workspace APIs (per-user) ==========

class WorkspaceBody(BaseModel):
    filename: str


@app.get("/workspace/{conversation_id}/files")
async def workspace_list(conversation_id: str, user: str = Depends(require_user())):
    try:
        files = workspace_store.list_files(user, conversation_id)
        return JSONResponse(content={"files": files})
    except Exception as e:
        logger.error(f"workspace_listå¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "workspace list failed"})


@app.post("/workspace/{conversation_id}/files")
async def workspace_add(conversation_id: str, body: WorkspaceBody, user: str = Depends(require_user())):
    try:
        # ç®€å•æ ¡éªŒï¼šæ–‡ä»¶éœ€å­˜åœ¨äºè¯¥ä¼šè¯ç›®å½•
        # ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•å
        output_dir_name = conv_manager.get_output_dir_name(conversation_id)
        f = Path("outputs") / output_dir_name / body.filename
        if not f.exists():
            return JSONResponse(status_code=404, content={"error": "æ–‡ä»¶ä¸å­˜åœ¨äºè¯¥ä¼šè¯ç›®å½•"})
        workspace_store.add_file(user, conversation_id, body.filename)
        return JSONResponse(content={"success": True})
    except Exception as e:
        logger.error(f"workspace_addå¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "workspace add failed"})


@app.delete("/workspace/{conversation_id}/files")
async def workspace_remove(conversation_id: str, body: WorkspaceBody, user: str = Depends(require_user())):
    try:
        workspace_store.remove_file(user, conversation_id, body.filename)
        return JSONResponse(content={"success": True})
    except Exception as e:
        logger.error(f"workspace_removeå¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "workspace remove failed"})


@app.get("/workspace/{conversation_id}/categorized")
async def workspace_categorized(conversation_id: str, user: str = Depends(require_user())):
    """è·å–ä¼šè¯ç›®å½•ä¸‹çš„åˆ†ç±»æ–‡ä»¶åˆ—è¡¨åŠç»Ÿè®¡ä¿¡æ¯

    Returns:
        {
            "categories": {
                "å›¾ç‰‡": [{name, path, size_str, mtime_str, ...}, ...],
                "è§†é¢‘": [...],
                ...
            },
            "statistics": {
                "total_files": 10,
                "total_size": "25.6 MB",
                "by_category": {"å›¾ç‰‡": 5, "è§†é¢‘": 2, ...}
            }
        }
    """
    try:
        # æƒé™æ ¡éªŒ
        conv = conv_manager.get_conversation(conversation_id, username=user)
        if not conv:
            return JSONResponse(status_code=404, content={"error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™"})

        # è·å–åˆ†ç±»æ–‡ä»¶åˆ—è¡¨
        categorized = workspace_manager.get_conversation_files(conversation_id)

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        statistics = workspace_manager.get_statistics(conversation_id)

        return JSONResponse(content={
            "categories": categorized,
            "statistics": statistics
        })
    except Exception as e:
        logger.error(f"workspace_categorizedå¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "è·å–åˆ†ç±»æ–‡ä»¶å¤±è´¥"})


@app.get("/workspace/user/all")
async def workspace_user_all(user: str = Depends(require_user())):
    """è·å–ç”¨æˆ·æ‰€æœ‰ä¼šè¯çš„åˆ†ç±»æ–‡ä»¶åˆ—è¡¨åŠç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…åŒ…å«ç”¨æˆ·æ˜ç¡®ä¿å­˜çš„æ–‡ä»¶ï¼‰

    Returns:
        {
            "categories": {
                "å›¾ç‰‡": [{name, conversation_id, size_str, mtime_str, ...}, ...],
                "è§†é¢‘": [...],
                ...
            },
            "statistics": {
                "total_files": 50,
                "total_size": "125.6 MB",
                "by_category": {"å›¾ç‰‡": 25, "è§†é¢‘": 10, ...},
                "conversations": 5
            }
        }
    """
    try:
        # è·å–ç”¨æˆ·æ‰€æœ‰ä¼šè¯
        convs = conv_manager.list_conversations(model=None, username=user)
        conversation_ids = [c["id"] for c in convs]

        if not conversation_ids:
            return JSONResponse(content={
                "categories": {cat: [] for cat in workspace_manager.FILE_CATEGORIES.keys()},
                "statistics": {
                    "total_files": 0,
                    "total_size": "0 B",
                    "by_category": {},
                    "conversations": 0
                }
            })

        # è·å–ç”¨æˆ·æ‰€æœ‰å·²ä¿å­˜çš„æ–‡ä»¶ï¼ˆéœ€è¦ä¼ é€’workspace_storeï¼‰
        categorized = workspace_manager.get_user_files(user, conversation_ids, workspace_store)

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        statistics = workspace_manager.get_user_statistics(user, conversation_ids, workspace_store)

        return JSONResponse(content={
            "categories": categorized,
            "statistics": statistics
        })
    except Exception as e:
        logger.error(f"workspace_user_allå¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"error": "è·å–ç”¨æˆ·æ–‡ä»¶å¤±è´¥"})


# ==================== ç”¨æˆ·åé¦ˆ API ====================

@app.post("/api/feedback")
async def submit_feedback(
    request: Request,
    user: str = Depends(require_user())
):
    """
    æ¥æ”¶ç”¨æˆ·åé¦ˆ

    è¯·æ±‚ä½“ç¤ºä¾‹:
    {
        "type": "feature",
        "content": "å¸Œæœ›å¢åŠ XXXåŠŸèƒ½",
        "contact": "user@example.com",
        "timestamp": "2024-01-01T12:00:00Z",
        "conversation_id": "conv123",
        "user_agent": "Mozilla/5.0..."
    }
    """
    try:
        data = await request.json()

        # éªŒè¯å¿…å¡«å­—æ®µ
        if not data.get('type'):
            return JSONResponse(
                status_code=400,
                content={"error": "åé¦ˆç±»å‹ä¸èƒ½ä¸ºç©º"}
            )

        if not data.get('content') or len(data.get('content', '').strip()) < 10:
            return JSONResponse(
                status_code=400,
                content={"error": "åé¦ˆå†…å®¹è‡³å°‘éœ€è¦10ä¸ªå­—ç¬¦"}
            )

        # å‡†å¤‡åé¦ˆæ•°æ®
        feedback_entry = {
            "username": user,
            "type": data.get('type'),
            "content": data.get('content'),
            "contact": data.get('contact', ''),
            "timestamp": data.get('timestamp'),
            "conversation_id": data.get('conversation_id', ''),
            "user_agent": data.get('user_agent', '')
        }

        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        feedback_file = Path("outputs") / "feedback.jsonl"
        try:
            with open(feedback_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(feedback_entry, ensure_ascii=False) + '\n')
            logger.info(f"æ”¶åˆ°ç”¨æˆ·åé¦ˆ [{user}] - {data.get('type')}")
        except Exception as e:
            logger.error(f"ä¿å­˜åé¦ˆå¤±è´¥: {e}")
            # å³ä½¿ä¿å­˜å¤±è´¥ä¹Ÿè¿”å›æˆåŠŸï¼Œé¿å…å½±å“ç”¨æˆ·ä½“éªŒ

        return JSONResponse(content={
            "success": True,
            "message": "æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼"
        })

    except Exception as e:
        logger.error(f"å¤„ç†åé¦ˆå¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "æäº¤åé¦ˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"}
        )


if __name__ == "__main__":
    import uvicorn
    # é…ç½®uvicornä»¥æ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„è¯·æ±‚ï¼ˆå¦‚MiniMaxç”Ÿæˆä»»åŠ¡ï¼‰
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=80,
        timeout_keep_alive=650,  # keepaliveè¶…æ—¶: 10åˆ†50ç§’ï¼ˆç•¥å¤§äºæœ€é•¿ä»»åŠ¡æ—¶é—´ï¼‰
        limit_concurrency=100     # å¹¶å‘é™åˆ¶
    )
