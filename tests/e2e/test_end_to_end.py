#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬ï¼šæ ·æœ¬æ‰§è¡Œ â†’ è¯„æµ‹

æµç¨‹ï¼š
1. åŠ è½½è¯„æµ‹æ ·æœ¬
2. ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«æ‰§è¡Œä»»åŠ¡
3. ä¿å­˜æ‰§è¡Œç»“æœ
4. è¿è¡Œè¯„æµ‹æ¡†æ¶
"""

import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.utils.config import get_config
from src.agent.master_agent import MasterAgent
from src.tools.registry import ToolRegistry
from src.tools.atomic.web_search import WebSearchTool
from src.tools.atomic.url_fetch import URLFetchTool
from src.tools.atomic.code_executor import CodeExecutor
from evaluator import EvaluationOrchestrator


def setup_agent(model_name: str) -> MasterAgent:
    """åˆå§‹åŒ–Agent"""
    config = get_config()
    tool_registry = ToolRegistry()

    # æ³¨å†Œå·¥å…·
    tool_registry.register_atomic_tool(WebSearchTool(config))
    tool_registry.register_atomic_tool(URLFetchTool(config))
    tool_registry.register_atomic_tool(CodeExecutor(config))

    agent = MasterAgent(config, tool_registry, model_name=model_name)
    return agent


def execute_task(agent: MasterAgent, query: str, sample_id: str, timeout: int = 300) -> dict:
    """æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›æ‰§è¡Œç»“æœ"""
    print(f"\nğŸ¤– æ¨¡å‹ {agent.llm.model_name} å¼€å§‹æ‰§è¡Œä»»åŠ¡...")
    print(f"ğŸ“ Query: {query}")

    # è®°å½•åˆå§‹çŠ¶æ€
    initial_state = {
        "files": []
    }

    # æ‰§è¡Œä»»åŠ¡
    try:
        result = agent.process(query)
        status = "success" if result.get("status") == "success" else "failed"
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        status = "failed"
        result = {"error": str(e)}

    # è·å–æœ€ç»ˆçŠ¶æ€ï¼ˆæ‰«æè¾“å‡ºç›®å½•ï¼‰
    output_dir = Path("outputs")
    conversation_id = agent.current_conversation_id

    final_files = []
    if conversation_id and output_dir.exists():
        conv_dir = output_dir / conversation_id
        if conv_dir.exists():
            for file_path in conv_dir.rglob("*"):
                if file_path.is_file():
                    rel_path = file_path.relative_to(conv_dir)
                    file_info = {
                        "path": str(rel_path),
                        "size": file_path.stat().st_size,
                        "type": file_path.suffix[1:] if file_path.suffix else "unknown"
                    }

                    # æ·»åŠ å›¾ç‰‡å…ƒæ•°æ®
                    if file_info["type"] in ["png", "jpg", "jpeg"]:
                        try:
                            from PIL import Image
                            img = Image.open(file_path)
                            file_info["metadata"] = {
                                "dimensions": {
                                    "width": img.width,
                                    "height": img.height
                                }
                            }
                        except:
                            pass

                    final_files.append(file_info)

    final_state = {
        "files": final_files
    }

    # æ„å»ºæ‰§è¡Œç»“æœ
    execution_result = {
        "sample_id": sample_id,
        "model_name": agent.llm.model_name,
        "status": status,
        "evaluated_at": datetime.now().isoformat(),
        "initial_state": initial_state,
        "final_state": final_state,
        "conversation_history": agent.conversation_history
    }

    print(f"âœ… æ‰§è¡Œå®Œæˆï¼ç”Ÿæˆ {len(final_files)} ä¸ªæ–‡ä»¶")
    return execution_result


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("CreativeFlow ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 80)

    # 1. åŠ è½½æ ·æœ¬
    sample_path = Path("samples/EVAL_ICON_COLLECTION_TECH.json")
    print(f"\nğŸ“‚ åŠ è½½æ ·æœ¬: {sample_path}")

    with open(sample_path, 'r', encoding='utf-8') as f:
        sample = json.load(f)

    sample_id = sample["data_id"]
    query = sample["query"]
    model_a = sample["models"]["model_a"]
    model_b = sample["models"]["model_b"]
    timeout = sample.get("timeout", 300)

    print(f"âœ“ æ ·æœ¬ID: {sample_id}")
    print(f"âœ“ Model A: {model_a}")
    print(f"âœ“ Model B: {model_b}")
    print(f"âœ“ è¶…æ—¶: {timeout}ç§’")

    # 2. æ‰§è¡ŒModel A
    print("\n" + "=" * 80)
    print("é˜¶æ®µ1: æ‰§è¡Œ Model A")
    print("=" * 80)

    agent_a = setup_agent(model_a)
    execution_result_a = execute_task(agent_a, query, sample_id, timeout)

    # ä¿å­˜æ‰§è¡Œç»“æœA
    execution_a_path = Path(f"executions/{model_a}_{sample_id}.json")
    execution_a_path.parent.mkdir(exist_ok=True)
    with open(execution_a_path, 'w', encoding='utf-8') as f:
        json.dump(execution_result_a, f, indent=2, ensure_ascii=False)
    print(f"âœ“ æ‰§è¡Œç»“æœå·²ä¿å­˜: {execution_a_path}")

    # 3. æ‰§è¡ŒModel B
    print("\n" + "=" * 80)
    print("é˜¶æ®µ2: æ‰§è¡Œ Model B")
    print("=" * 80)

    agent_b = setup_agent(model_b)
    execution_result_b = execute_task(agent_b, query, sample_id, timeout)

    # ä¿å­˜æ‰§è¡Œç»“æœB
    execution_b_path = Path(f"executions/{model_b}_{sample_id}.json")
    with open(execution_b_path, 'w', encoding='utf-8') as f:
        json.dump(execution_result_b, f, indent=2, ensure_ascii=False)
    print(f"âœ“ æ‰§è¡Œç»“æœå·²ä¿å­˜: {execution_b_path}")

    # 4. è¿è¡Œè¯„æµ‹
    print("\n" + "=" * 80)
    print("é˜¶æ®µ3: è¿è¡Œè¯„æµ‹æ¡†æ¶")
    print("=" * 80)

    # æ£€æŸ¥æ˜¯å¦éœ€è¦LLM Judge
    has_llm_judge = any(
        check["check_type"] == "llm_judge"
        for check in sample["check_list"]
    )

    if has_llm_judge:
        print("\nâš ï¸  æ ·æœ¬åŒ…å«LLM Judgeæ£€æŸ¥é¡¹")
        print("è¯·æä¾›Judgeæ¨¡å‹é…ç½®:")

        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®è¯»å–
        import os
        judge_model = os.getenv("JUDGE_MODEL", "claude-sonnet-4-5-20250929")
        judge_base_url = os.getenv("JUDGE_BASE_URL", "https://api.anthropic.com/v1")
        judge_api_key = os.getenv("ANTHROPIC_API_KEY")

        if not judge_api_key:
            print("âŒ æœªæ‰¾åˆ°ANTHROPIC_API_KEYç¯å¢ƒå˜é‡ï¼Œè·³è¿‡LLM Judge")
            judge_model = None
            judge_base_url = None
            judge_api_key = None
        else:
            print(f"âœ“ ä½¿ç”¨Judgeæ¨¡å‹: {judge_model}")
    else:
        judge_model = None
        judge_base_url = None
        judge_api_key = None

    # åˆ›å»ºè¯„æµ‹å™¨
    orchestrator = EvaluationOrchestrator(
        judge_model=judge_model,
        judge_base_url=judge_base_url,
        judge_api_key=judge_api_key
    )

    # æ‰§è¡Œè¯„æµ‹
    result_path = Path(f"results/{sample_id}_result.json")
    result_path.parent.mkdir(exist_ok=True)

    eval_result = orchestrator.evaluate(
        sample=sample,
        execution_result_a=execution_result_a,
        execution_result_b=execution_result_b,
        output_file=result_path
    )

    print(f"\nâœ“ è¯„æµ‹ç»“æœå·²ä¿å­˜: {result_path}")

    # 5. è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "=" * 80)
    print("è¯„æµ‹ç»“æœæ‘˜è¦")
    print("=" * 80)

    print(f"\nğŸ“Š Model A ({model_a}):")
    print(f"  - çŠ¶æ€: {execution_result_a['status']}")
    print(f"  - æ–‡ä»¶æ•°: {len(execution_result_a['final_state']['files'])}")

    print(f"\nğŸ“Š Model B ({model_b}):")
    print(f"  - çŠ¶æ€: {execution_result_b['status']}")
    print(f"  - æ–‡ä»¶æ•°: {len(execution_result_b['final_state']['files'])}")

    print("\nâœ… ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ!")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. æŸ¥çœ‹æ‰§è¡Œç»“æœæ–‡ä»¶:")
    print(f"   - {execution_a_path}")
    print(f"   - {execution_b_path}")
    print("2. æŸ¥çœ‹è¯„æµ‹ç»“æœ:")
    print(f"   - {result_path}")
    print("3. è¿›è¡ŒHuman Annotationï¼ˆå¦‚æœéœ€è¦ï¼‰")


if __name__ == "__main__":
    main()
