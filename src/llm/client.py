"""LLMå®¢æˆ·ç«¯æ¨¡å—

æä¾›ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹åˆ‡æ¢ã€‚
"""

import requests
import time
import random
from typing import List, Dict, Optional, Any
from src.utils.config import Config
from src.utils.logger import get_logger

logger = get_logger(__name__)


class LLMClient:
    """ç»Ÿä¸€LLMå®¢æˆ·ç«¯

    æ”¯æŒé€šè¿‡model_nameå‚æ•°åˆ‡æ¢ä¸åŒçš„LLMæ¨¡å‹ã€‚
    """

    def __init__(self, config: Config, model_name: str = "ernie-5.0-thinking-preview"):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯

        Args:
            config: é…ç½®å¯¹è±¡
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºEB5
        """
        self.config = config
        self.model_name = model_name
        self.model_config = config.get_model_config(model_name)
        # ç®€å•çš„é‡è¯•ç­–ç•¥ï¼šæœ€å¤š5æ¬¡ï¼ŒæŒ‡æ•°é€€é¿åŸºç¡€é—´éš”0.5s
        self.max_retries = 5
        self.retry_base_delay = 0.5

        logger.info(f"åˆå§‹åŒ–LLMClient: model={model_name}, base_url={self.model_config['base_url']}")

    # ===== Claude native helpers =====
    def _is_claude(self) -> bool:
        return str(self.model_name).lower().startswith("claude")

    def _is_gemini(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºGeminiæ¨¡å‹"""
        return "gemini" in str(self.model_name).lower()

    def _build_claude_native_url(self) -> str:
        """æ„é€ ClaudeåŸç”Ÿmessagesç«¯ç‚¹ã€‚
        ä¼˜å…ˆä½¿ç”¨é…ç½®CLAUDE_API_BASE_URLï¼Œå¦åˆ™ä»ç»Ÿä¸€ç½‘å…³base_urlæ›¿æ¢æˆ/v1/messagesã€‚
        """
        import urllib.parse
        base = self.model_config.get("base_url") or ""
        if getattr(self.config, 'claude_api_base_url', None):
            return self.config.claude_api_base_url
        try:
            u = urllib.parse.urlparse(base)
            return f"{u.scheme}://{u.netloc}/v1/messages"
        except Exception:
            return base

    def _convert_tools_to_anthropic(self, tools: Optional[List[Dict[str, Any]]]) -> Optional[List[Dict[str, Any]]]:
        if not tools:
            return None
        out = []
        for t in tools:
            fn = (t or {}).get("function") or {}
            out.append({
                "name": fn.get("name", ""),
                "description": fn.get("description", ""),
                "input_schema": fn.get("parameters", {"type": "object"})
            })
        return out

    # ===== Gemini native helpers =====
    def _convert_tools_to_gemini(self, tools: Optional[List[Dict[str, Any]]]) -> Optional[List[Dict[str, Any]]]:
        """å°†OpenAIæ ¼å¼çš„toolsè½¬æ¢ä¸ºGeminiæ ¼å¼

        OpenAI: {"type": "function", "function": {"name": "...", "parameters": {...}}}
        Gemini: {"functionDeclarations": [{"name": "...", "parameters": {...}}]}
        """
        if not tools:
            return None

        declarations = []
        for t in tools:
            fn = (t or {}).get("function") or {}
            params = fn.get("parameters", {})

            # è½¬æ¢å‚æ•°ç±»å‹ä¸ºå¤§å†™ï¼ˆGeminiè¦æ±‚ï¼‰
            gemini_params = self._convert_schema_types_to_uppercase(params)

            declarations.append({
                "name": fn.get("name", ""),
                "description": fn.get("description", ""),
                "parameters": gemini_params
            })

        return [{"functionDeclarations": declarations}]

    def _convert_schema_types_to_uppercase(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """é€’å½’è½¬æ¢schemaä¸­çš„typeå­—æ®µä¸ºå¤§å†™ï¼ˆGeminiæ ¼å¼è¦æ±‚ï¼‰

        object -> OBJECT, string -> STRING, integer -> INTEGER, array -> ARRAY
        """
        if not isinstance(schema, dict):
            return schema

        result = {}
        for key, value in schema.items():
            if key == "type" and isinstance(value, str):
                # ç±»å‹æ˜ å°„
                type_mapping = {
                    "object": "OBJECT",
                    "string": "STRING",
                    "integer": "INTEGER",
                    "number": "NUMBER",
                    "boolean": "BOOLEAN",
                    "array": "ARRAY"
                }
                result[key] = type_mapping.get(value.lower(), value.upper())
            elif isinstance(value, dict):
                result[key] = self._convert_schema_types_to_uppercase(value)
            elif isinstance(value, list):
                result[key] = [self._convert_schema_types_to_uppercase(item) if isinstance(item, dict) else item for item in value]
            else:
                result[key] = value

        return result

    def _convert_messages_to_contents(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å°†OpenAIæ ¼å¼çš„messagesè½¬æ¢ä¸ºGeminiæ ¼å¼çš„contents

        OpenAI: [{"role": "user/assistant/system", "content": "..."}]
        Gemini: [{"role": "user/model", "parts": [{"text": "..."}]}]

        æ³¨æ„ï¼š
        - systemæ¶ˆæ¯ä¼šè¢«åˆå¹¶åˆ°ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯å‰
        - assistant -> model
        - toolæ¶ˆæ¯è½¬æ¢ä¸ºfunctionResponseæ ¼å¼
        """
        contents = []
        system_instruction = None

        for msg in messages:
            role = msg.get("role", "").lower()
            content = msg.get("content", "")

            if role == "system":
                # Geminiå°†systemä½œä¸ºç‹¬ç«‹é…ç½®ï¼Œæš‚å­˜
                system_instruction = content
                continue

            if role == "assistant":
                # assistant -> model
                gemini_role = "model"

                # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰GeminiåŸç”Ÿpartsï¼ˆå³ä½¿tool_callsè¢«ç§»é™¤ï¼Œä¹Ÿè¦ä½¿ç”¨ï¼‰
                gemini_parts = msg.get("_gemini_original_parts")
                if gemini_parts:
                    # ç›´æ¥ä½¿ç”¨åŸå§‹partsï¼Œä¿ç•™thoughtSignatureç­‰Geminiç‰¹æœ‰å­—æ®µ
                    contents.append({"role": gemini_role, "parts": gemini_parts})
                    continue  # è·³è¿‡åç»­å¤„ç†

                # æ£€æŸ¥æ˜¯å¦æœ‰tool_callsï¼ˆå…¼å®¹éGeminiæ¥æºï¼‰
                tool_calls = msg.get("tool_calls")
                if tool_calls:
                    # ğŸ”§ å®‰å…¨æ£€æŸ¥ï¼šGeminiæ¨¡å‹çš„tool_callså¿…é¡»æœ‰_gemini_original_parts
                    # å¦‚æœæ²¡æœ‰ï¼ˆæ—§ç‰ˆæœ¬æ¶ˆæ¯ï¼‰ï¼Œè½¬æ¢ä¼šç¼ºå°‘thoughtSignatureå¯¼è‡´400é”™è¯¯
                    # è§£å†³æ–¹æ¡ˆï¼šç›´æ¥è·³è¿‡è¿™æ¡æ¶ˆæ¯ï¼Œä¸æ‹¼æ¥åˆ°contentsé‡Œ
                    if self._is_gemini() and not gemini_parts:
                        logger.warning(f"æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬assistantæ¶ˆæ¯ï¼ˆæœ‰{len(tool_calls)}ä¸ªtool_callsä½†æ— _gemini_original_partsï¼‰ï¼Œç›´æ¥è·³è¿‡ä¸æ‹¼æ¥")
                        continue  # è·³è¿‡è¿™æ¡æ¶ˆæ¯
                    else:
                        # è½¬æ¢ä¸ºfunctionCallæ ¼å¼ï¼ˆå…¼å®¹éGeminiæ¥æºçš„tool_callsï¼‰
                        parts = []
                        for tc in tool_calls:
                            fn = tc.get("function", {})
                            import json
                            try:
                                args = json.loads(fn.get("arguments", "{}")) if isinstance(fn.get("arguments"), str) else fn.get("arguments", {})
                            except:
                                args = {}

                            parts.append({
                                "functionCall": {
                                    "name": fn.get("name", ""),
                                    "args": args
                                }
                            })

                        contents.append({"role": gemini_role, "parts": parts})
                else:
                    # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                    if content:
                        contents.append({
                            "role": gemini_role,
                            "parts": [{"text": str(content)}]
                        })

            elif role == "user":
                # Useræ¶ˆæ¯ï¼šæ”¯æŒçº¯æ–‡æœ¬å’Œmultimodal
                if isinstance(content, str):
                    # çº¯æ–‡æœ¬
                    contents.append({
                        "role": "user",
                        "parts": [{"text": str(content)}]
                    })
                elif isinstance(content, list):
                    # Multimodalæ¶ˆæ¯
                    parts = []
                    for part in content:
                        if not isinstance(part, dict):
                            continue

                        part_type = part.get("type")
                        if part_type == "text":
                            # æ–‡æœ¬éƒ¨åˆ†
                            parts.append({"text": part.get("text", "")})
                        elif part_type == "image_url":
                            # å›¾ç‰‡éƒ¨åˆ†ï¼šè½¬æ¢OpenAIæ ¼å¼åˆ°Geminiæ ¼å¼
                            # OpenAI: {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
                            # Gemini: {"inline_data": {"mime_type": "image/jpeg", "data": "..."}}
                            image_url_obj = part.get("image_url", {})
                            data_url = image_url_obj.get("url", "")

                            # è§£ædata URL
                            if data_url.startswith("data:"):
                                try:
                                    header, base64_data = data_url.split(",", 1)
                                    mime_type = header.split(":")[1].split(";")[0]

                                    parts.append({
                                        "inline_data": {
                                            "mime_type": mime_type,
                                            "data": base64_data
                                        }
                                    })
                                except Exception as e:
                                    logger.warning(f"è§£æGeminiå›¾ç‰‡data URLå¤±è´¥: {e}")

                    if parts:
                        contents.append({"role": "user", "parts": parts})
                else:
                    # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºæ–‡æœ¬
                    contents.append({
                        "role": "user",
                        "parts": [{"text": str(content)}]
                    })

            elif role == "tool":
                # toolç»“æœè½¬æ¢ä¸ºfunctionResponse
                # æ³¨æ„ï¼šGeminiè¦æ±‚functionResponseå¿…é¡»åœ¨useræ¶ˆæ¯ä¸­ï¼Œä»¥ä¿æŒuser/modeläº¤æ›¿
                tool_name = msg.get("name", "unknown")
                tool_response = {
                    "functionResponse": {
                        "name": tool_name,
                        "response": {
                            "content": str(content)
                        }
                    }
                }
                contents.append({
                    "role": "user",  # functionResponseå¿…é¡»ä½¿ç”¨user role
                    "parts": [tool_response]
                })

        # å¦‚æœæœ‰system instructionï¼Œæ’å…¥åˆ°å¼€å¤´ï¼ˆæˆ–ä½œä¸ºé…ç½®è¿”å›ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå¦‚æœæœ‰systemï¼Œæ·»åŠ åˆ°ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯å‰
        if system_instruction and contents:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯
            for i, c in enumerate(contents):
                if c.get("role") == "user":
                    # å°†system instructionæ·»åŠ åˆ°è¯¥useræ¶ˆæ¯çš„å¼€å¤´
                    parts = c.get("parts", [])
                    parts.insert(0, {"text": f"[System Instructions: {system_instruction}]\n\n"})
                    break

        # Geminiè¦æ±‚ï¼šå¿…é¡»user/modeläº¤æ›¿ï¼Œä¸”ä»¥userå¼€å§‹
        # åˆå¹¶è¿ç»­çš„ç›¸åŒroleæ¶ˆæ¯
        merged_contents = []
        for content_msg in contents:
            if not merged_contents:
                merged_contents.append(content_msg)
            elif merged_contents[-1]["role"] == content_msg["role"]:
                # ç›¸åŒroleï¼Œåˆå¹¶parts
                last_parts = merged_contents[-1]["parts"]
                current_parts = content_msg["parts"]

                # æ™ºèƒ½åˆå¹¶ï¼šå¦‚æœéƒ½æ˜¯textï¼Œåˆå¹¶æ–‡æœ¬å†…å®¹ï¼›å¦åˆ™ç›´æ¥extend
                if (len(last_parts) == 1 and "text" in last_parts[0] and
                    len(current_parts) == 1 and "text" in current_parts[0]):
                    # åˆå¹¶ä¸¤ä¸ªtext partsä¸ºä¸€ä¸ª
                    last_parts[0]["text"] += "\n\n" + current_parts[0]["text"]
                else:
                    # å…¶ä»–æƒ…å†µï¼ˆfunctionCallã€functionResponseç­‰ï¼‰ç›´æ¥extend
                    merged_contents[-1]["parts"].extend(content_msg["parts"])
            else:
                merged_contents.append(content_msg)

        # ç¡®ä¿ä»¥userå¼€å§‹
        if merged_contents and merged_contents[0]["role"] != "user":
            merged_contents.insert(0, {
                "role": "user",
                "parts": [{"text": "Continue."}]
            })

        return merged_contents

    def _sanitize_inf_values(self, obj):
        """é€’å½’æ¸…ç†å¯¹è±¡ä¸­çš„inf/-infå€¼ï¼Œæ›¿æ¢ä¸ºNone

        JSONæ ‡å‡†ä¸æ”¯æŒinfå€¼ï¼Œéœ€è¦æ¸…ç†æ‰
        """
        import math

        if isinstance(obj, float):
            if math.isinf(obj) or math.isnan(obj):
                logger.warning(f"å‘ç°éæ³•æµ®ç‚¹æ•°å€¼: {obj}ï¼Œæ›¿æ¢ä¸ºNone")
                return None
            return obj
        elif isinstance(obj, dict):
            return {k: self._sanitize_inf_values(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._sanitize_inf_values(item) for item in obj]
        else:
            return obj

    def _remove_orphaned_tool_messages(self, msgs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç§»é™¤å­¤ç«‹çš„toolæ¶ˆæ¯ï¼ˆæ²¡æœ‰å¯¹åº”tool_useçš„tool_resultï¼‰

        Claude/Bedrockä¸¥æ ¼è¦æ±‚ï¼štoolæ¶ˆæ¯å¿…é¡»ç´§è·Ÿåœ¨åŒ…å«å¯¹åº”tool_useçš„assistantæ¶ˆæ¯ä¹‹å
        """
        cleaned = []
        last_assistant_tool_ids = set()

        for m in msgs:
            role = (m.get("role") or "").lower()

            if role == "assistant":
                # é‡ç½®å¹¶è®°å½•æ–°çš„tool_use IDs
                last_assistant_tool_ids.clear()
                tcs = m.get("tool_calls") or []
                for tc in tcs:
                    tid = (tc or {}).get("id")
                    if tid:
                        last_assistant_tool_ids.add(tid)
                cleaned.append(m)

            elif role == "tool":
                # éªŒè¯tool_call_id
                tool_call_id = m.get("tool_call_id") or m.get("id") or ""
                if tool_call_id in last_assistant_tool_ids:
                    cleaned.append(m)
                    last_assistant_tool_ids.discard(tool_call_id)
                else:
                    logger.warning(f"[æ¶ˆæ¯æ¸…ç†] è·³è¿‡å­¤ç«‹çš„toolæ¶ˆæ¯: tool_call_id={tool_call_id}, last_assistant_tool_ids={last_assistant_tool_ids}")

            elif role == "user":
                # useræ¶ˆæ¯æ‰“æ–­åºåˆ—ï¼Œæ¸…ç©ºtool_ids
                last_assistant_tool_ids.clear()
                cleaned.append(m)

            else:
                # systemç­‰å…¶ä»–æ¶ˆæ¯ç›´æ¥ä¿ç•™
                cleaned.append(m)

        removed_count = len(msgs) - len(cleaned)
        if removed_count > 0:
            logger.info(f"[æ¶ˆæ¯æ¸…ç†] ç§»é™¤äº† {removed_count} æ¡å­¤ç«‹çš„toolæ¶ˆæ¯")

        return cleaned

    def _build_anthropic_messages_payload(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]], temperature: float, max_tokens: Optional[int]) -> Dict[str, Any]:
        import json as _json
        system_parts: List[str] = []
        anth_msgs: List[Dict[str, Any]] = []

        # è·Ÿè¸ªæœ€åä¸€æ¡assistantæ¶ˆæ¯ä¸­çš„tool_use IDsï¼ˆClaudeè¦æ±‚tool_resultå¿…é¡»åœ¨previous messageä¸­æœ‰å¯¹åº”tool_useï¼‰
        last_assistant_tool_ids: set = set()

        for m in messages:
            role = (m.get("role") or "user").lower()
            content = m.get("content")
            if role == "system":
                if isinstance(content, str):
                    system_parts.append(content)
                else:
                    system_parts.append(str(content))
                continue

            if role == "tool":
                # å·¥å…·ç»“æœ â†’ useræ¶ˆæ¯ä¸­çš„tool_resultå—
                tool_use_id = m.get("tool_call_id") or m.get("id") or ""

                # éªŒè¯ï¼šåªæœ‰å½“tool_use_idåœ¨æœ€åä¸€æ¡assistantæ¶ˆæ¯ä¸­æ—¶æ‰æ·»åŠ tool_result
                if tool_use_id not in last_assistant_tool_ids:
                    logger.warning(f"è·³è¿‡å­¤ç«‹çš„toolæ¶ˆæ¯: tool_call_id={tool_use_id} æ²¡æœ‰åœ¨previous assistantæ¶ˆæ¯ä¸­æ‰¾åˆ°å¯¹åº”çš„tool_use")
                    logger.warning(f"  last_assistant_tool_ids={last_assistant_tool_ids}")
                    # æ¸…ç©ºï¼Œå› ä¸ºåºåˆ—å·²æ–­
                    last_assistant_tool_ids.clear()
                    continue

                result_text = str(m.get("content") or "")
                anth_msgs.append({
                    "role": "user",
                    "content": [
                        {
                            "type": "tool_result",
                            "tool_use_id": tool_use_id,
                            "content": [{"type": "text", "text": result_text or "(empty)"}]
                        }
                    ]
                })
                # å·¥å…·ç»“æœæ·»åŠ åï¼Œä»é›†åˆä¸­ç§»é™¤è¿™ä¸ªID
                # é˜²æ­¢é‡å¤çš„tool_resultå¼•ç”¨åŒä¸€ä¸ªtool_use_id
                last_assistant_tool_ids.discard(tool_use_id)
                continue

            if role == "assistant":
                # é‡ç½®ï¼šæ¯æ¬¡é‡åˆ°æ–°çš„assistantæ¶ˆæ¯æ—¶ï¼Œæ¸…ç©ºå¹¶è®°å½•æ–°çš„tool_use IDs
                last_assistant_tool_ids.clear()

                blocks: List[Dict[str, Any]] = []
                if isinstance(content, str) and content.strip() and content != "(tool call)":
                    blocks.append({"type": "text", "text": content})
                tcs = m.get("tool_calls") or []
                for i, tc in enumerate(tcs):
                    fn = (tc or {}).get("function") or {}
                    name = fn.get("name", "")
                    args = fn.get("arguments")
                    try:
                        args_obj = _json.loads(args) if isinstance(args, str) else (args or {})
                    except Exception:
                        args_obj = {}
                    tid = (tc or {}).get("id") or f"tu_{int(time.time()*1000)}_{i}"

                    # è®°å½•è¿™ä¸ªtool_use_id
                    last_assistant_tool_ids.add(tid)

                    blocks.append({
                        "type": "tool_use",
                        "id": tid,
                        "name": name,
                        "input": args_obj,
                    })
                if not blocks:
                    blocks = [{"type": "text", "text": content or "â€¦"}]
                anth_msgs.append({"role": "assistant", "content": blocks})
                continue

            # é»˜è®¤æŒ‰userå¤„ç†
            # é‡è¦ï¼šé‡åˆ°useræ¶ˆæ¯æ—¶ï¼Œæ¸…ç©ºlast_assistant_tool_ids
            # å› ä¸ºClaudeè¦æ±‚tool_resultå¿…é¡»åœ¨previous messageä¸­æœ‰å¯¹åº”tool_use
            # ä¸€æ—¦æ’å…¥useræ¶ˆæ¯ï¼Œä¹‹åçš„tool_resultå°±æ— æ³•å†å¼•ç”¨å‰é¢çš„tool_useäº†
            last_assistant_tool_ids.clear()

            if isinstance(content, str):
                # çº¯æ–‡æœ¬æ¶ˆæ¯
                text = content if content.strip() else "â€¦"
                anth_msgs.append({"role": "user", "content": [{"type": "text", "text": text}]})
            elif isinstance(content, list):
                # Multimodalæ¶ˆæ¯ï¼ˆåŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡ï¼‰
                blocks: List[Dict[str, Any]] = []
                for part in content:
                    if not isinstance(part, dict):
                        continue

                    part_type = part.get("type")
                    if part_type == "text":
                        # æ–‡æœ¬éƒ¨åˆ†
                        blocks.append({"type": "text", "text": part.get("text", "")})
                    elif part_type == "image_url":
                        # å›¾ç‰‡éƒ¨åˆ†ï¼šè½¬æ¢OpenAIæ ¼å¼åˆ°Claudeæ ¼å¼
                        # OpenAI: {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
                        # Claude: {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": "..."}}
                        image_url_obj = part.get("image_url", {})
                        data_url = image_url_obj.get("url", "")

                        # è§£ædata URL: data:image/jpeg;base64,<base64_data>
                        if data_url.startswith("data:"):
                            try:
                                # æå–media_typeå’Œbase64æ•°æ®
                                header, base64_data = data_url.split(",", 1)
                                media_type = header.split(":")[1].split(";")[0]  # image/jpeg

                                blocks.append({
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": media_type,
                                        "data": base64_data
                                    }
                                })
                            except Exception as e:
                                logger.warning(f"è§£æå›¾ç‰‡data URLå¤±è´¥: {e}")

                if not blocks:
                    blocks = [{"type": "text", "text": "â€¦"}]
                anth_msgs.append({"role": "user", "content": blocks})
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºæ–‡æœ¬
                text = str(content) if content else "â€¦"
                anth_msgs.append({"role": "user", "content": [{"type": "text", "text": text}]})

        payload = {
            "model": self.model_config["model"],
            "messages": anth_msgs,
            "temperature": temperature,
            "max_tokens": int(max_tokens or 2048),
        }
        if system_parts:
            payload["system"] = "\n\n".join(system_parts)
        ant_tools = self._convert_tools_to_anthropic(tools)
        if ant_tools:
            payload["tools"] = ant_tools
            payload["tool_choice"] = {"type": "auto"}
        return payload

    def chat(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        stream: bool = False,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None
    ):
        """å‘é€èŠå¤©è¯·æ±‚

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼‰
            max_tokens: æœ€å¤§tokenæ•°
            stream: æ˜¯å¦æµå¼è¾“å‡º
            tools: Function Callingå·¥å…·åˆ—è¡¨
            tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥ ("auto", "none", æˆ–æŒ‡å®šå·¥å…·å)

        Returns:
            å¦‚æœstream=Trueï¼Œè¿”å›ç”Ÿæˆå™¨ï¼›å¦åˆ™è¿”å›å“åº”å­—å…¸

        Raises:
            requests.exceptions.RequestException: è¯·æ±‚å¤±è´¥
        """
        if stream:
            return self._chat_stream(messages, temperature, max_tokens, tools, tool_choice)
        else:
            return self._chat_non_stream(messages, temperature, max_tokens, tools, tool_choice)

    def _chat_non_stream(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None
    ) -> Dict[str, Any]:
        """éæµå¼èŠå¤©è¯·æ±‚

        Returns:
            å“åº”å­—å…¸ï¼ŒåŒ…å«contentã€usageã€tool_callsç­‰ä¿¡æ¯
        """
        # æ„å»ºè¯·æ±‚ä½“
        # Claude(Bedrock)é€‚é…ï¼šä¸å…è®¸ç©ºcontentï¼›æœ€å°åŒ–å…¼å®¹ï¼ˆä»ä½¿ç”¨OAIæ ·å¼ï¼Œç”±ç½‘å…³è½¬æ¢ï¼‰
        def _sanitize_msgs_for_claude(msgs: List[Dict[str, Any]]):
            out = []
            for m in msgs:
                c = m.get("content")
                if isinstance(c, str) and (c.strip() == "" or c is None):
                    m = dict(m)
                    m["content"] = "â€¦"
                out.append(m)
            return out

        used_messages = messages
        used_tools = tools
        if str(self.model_name).lower().startswith("claude"):
            used_messages = _sanitize_msgs_for_claude(messages)
            # æ¸…ç†å­¤ç«‹çš„toolæ¶ˆæ¯ï¼ˆBedrockåç«¯ä¸¥æ ¼è¦æ±‚ï¼‰
            used_messages = self._remove_orphaned_tool_messages(used_messages)

        payload = {
            "model": self.model_config["model"],
            "messages": used_messages,
            "temperature": temperature,
            "stream": False
        }

        if max_tokens:
            payload["max_tokens"] = max_tokens

        # Reasoning effortå‚æ•°ï¼ˆä»…OpenAIæ¨¡å‹æ”¯æŒï¼‰
        if not str(self.model_name).lower().startswith("claude"):
            payload["reasoning_effort"] = "high"

        # Function Callingå‚æ•°
        if used_tools:
            payload["tools"] = used_tools
            if tool_choice:
                payload["tool_choice"] = tool_choice

        # æ„å»ºheaders
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.model_config['api_key']}"
        }
        if str(self.model_name).lower().startswith("claude"):
            headers["anthropic-version"] = headers.get("anthropic-version", "2023-06-01")

        # è®°å½•è¯·æ±‚æ—¥å¿—ï¼ˆè„±æ•ï¼‰
        if self.config.agent_enable_request_logging:
            try:
                msg_preview = [
                    {"role": m.get("role"), "len": len(m.get("content", ""))}
                    for m in (messages or [])
                ]
                logger.debug(
                    f"LLMè¯·æ±‚: model={self.model_name}, stream=False, messages={msg_preview}, tools={len(tools) if tools else 0}, tool_choice={tool_choice}"
                )
            except Exception:
                pass

        last_error = None
        for attempt in range(1, self.max_retries + 1):
            try:
                response = requests.post(
                    self.model_config["base_url"],
                    headers=headers,
                    json=payload,
                    timeout=self.model_config["timeout"]
                )
                if response.status_code >= 400:
                    detail = None
                    try:
                        detail = response.text[:500]
                    except Exception:
                        detail = None
                    logger.error(
                        f"LLMéæµå¼è¯·æ±‚å¤±è´¥: status={response.status_code}, detail={detail}"
                    )
                    # 4xx(é429)ä¸å†é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
                    if 400 <= response.status_code < 500 and response.status_code != 429:
                        response.raise_for_status()
                response.raise_for_status()

                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    response_dict = {
                        "content": message.get("content"),
                        "model": self.model_name,
                        "usage": result.get("usage", {}),
                        "raw_response": result
                    }
                    if "tool_calls" in message:
                        response_dict["tool_calls"] = message["tool_calls"]
                    return response_dict
                else:
                    raise ValueError(f"æ— æ•ˆçš„LLMå“åº”æ ¼å¼: {result}")

            except (requests.exceptions.Timeout, requests.exceptions.RequestException) as e:
                last_error = e
                # è‹¥æ˜¯4xxä¸”é429ï¼Œä¸é‡è¯•
                try:
                    status = getattr(e.response, "status_code", None)
                except Exception:
                    status = None
                if status is not None and 400 <= status < 500 and status != 429:
                    logger.error(f"LLMè¯·æ±‚å¤±è´¥(4xx,ä¸é‡è¯•): {e}")
                    raise
                if attempt >= self.max_retries:
                    logger.error(f"LLMè¯·æ±‚å¤±è´¥ä¸”é‡è¯•è€—å°½({attempt}/{self.max_retries}): {e}")
                    raise

                # é’ˆå¯¹429é€Ÿç‡é™åˆ¶ä½¿ç”¨æ›´æ¿€è¿›çš„é€€é¿ç­–ç•¥
                if status == 429:
                    # 429é”™è¯¯ï¼šä½¿ç”¨æ›´é•¿çš„æŒ‡æ•°é€€é¿ï¼Œä»2ç§’å¼€å§‹
                    delay = 2.0 * (2 ** (attempt - 1))  # 2s, 4s, 8s, 16s, 32s
                    delay += random.uniform(0, 1.0)  # æ·»åŠ æŠ–åŠ¨é¿å…é›·é¸£ç¾¤æ•ˆåº”
                    logger.warning(f"é‡åˆ°é€Ÿç‡é™åˆ¶(429)ï¼Œä½¿ç”¨é•¿é€€é¿ç­–ç•¥ï¼Œé‡è¯•ç¬¬{attempt}/{self.max_retries}æ¬¡ï¼Œç­‰å¾…{delay:.2f}s: {e}")
                else:
                    # å…¶ä»–é”™è¯¯ï¼šä½¿ç”¨æ ‡å‡†æŒ‡æ•°é€€é¿
                    delay = self.retry_base_delay * (2 ** (attempt - 1))
                    delay += random.uniform(0, self.retry_base_delay)
                    logger.warning(f"LLMè¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ç¬¬{attempt}/{self.max_retries}æ¬¡åé‡è¯•ï¼Œç­‰å¾…{delay:.2f}s: {e}")

                time.sleep(delay)

    def generate_code(
        self,
        task_description: str,
        context: Optional[str] = None,
        language: str = "python"
    ) -> str:
        """ç”Ÿæˆä»£ç 

        Args:
            task_description: ä»»åŠ¡æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æ•°æ®ç¤ºä¾‹ï¼‰
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            ç”Ÿæˆçš„ä»£ç å­—ç¬¦ä¸²
        """
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}ç¨‹åºå‘˜ã€‚
æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œç”Ÿæˆç®€æ´ã€å¯æ‰§è¡Œçš„ä»£ç ã€‚

è¦æ±‚ï¼š
1. ä»£ç å¿…é¡»å®Œæ•´å¯æ‰§è¡Œ
2. åŒ…å«å¿…è¦çš„é”™è¯¯å¤„ç†
3. åªè¾“å‡ºä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Š
4. ä»£ç ç”¨```{language}åŒ…è£¹"""

        user_prompt = f"ä»»åŠ¡ï¼š{task_description}"
        if context:
            user_prompt += f"\n\nä¸Šä¸‹æ–‡ï¼š\n{context}"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = self.chat(messages, temperature=0.2)  # ä»£ç ç”Ÿæˆç”¨ä½æ¸©åº¦
        content = response["content"]

        # æå–ä»£ç å—
        code = self._extract_code_block(content, language)

        logger.info(f"ä»£ç ç”ŸæˆæˆåŠŸ: {len(code)} characters")
        return code

    def analyze_text(
        self,
        text: str,
        analysis_type: str,
        instructions: Optional[str] = None
    ) -> str:
        """æ–‡æœ¬åˆ†æï¼ˆæƒ…æ„Ÿã€ä¸»é¢˜ã€æ‘˜è¦ç­‰ï¼‰

        Args:
            text: å¾…åˆ†ææ–‡æœ¬
            analysis_type: åˆ†æç±»å‹ï¼ˆsentiment/topic/summaryï¼‰
            instructions: é¢å¤–æŒ‡ä»¤

        Returns:
            åˆ†æç»“æœ
        """
        analysis_prompts = {
            "sentiment": "åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ï¼Œå¹¶ç»™å‡ºç†ç”±ã€‚",
            "topic": "æå–ä»¥ä¸‹æ–‡æœ¬çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®è¯ã€‚",
            "summary": "å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œç®€æ´çš„æ‘˜è¦ã€‚"
        }

        system_prompt = analysis_prompts.get(analysis_type, "åˆ†æä»¥ä¸‹æ–‡æœ¬ã€‚")
        if instructions:
            system_prompt += f"\n\né¢å¤–è¦æ±‚ï¼š{instructions}"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text}
        ]

        response = self.chat(messages, temperature=0.3)
        return response["content"]

    def _extract_code_block(self, content: str, language: str) -> str:
        """ä»LLMå“åº”ä¸­æå–ä»£ç å—

        Args:
            content: LLMå“åº”å†…å®¹
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            æå–çš„ä»£ç 
        """
        # å°è¯•æå–```language code ```æ ¼å¼
        import re

        pattern = f"```{language}\\s*\\n(.*?)\\n```"
        match = re.search(pattern, content, re.DOTALL)

        if match:
            return match.group(1).strip()

        # å°è¯•æå–```code```æ ¼å¼
        pattern = "```\\s*\\n(.*?)\\n```"
        match = re.search(pattern, content, re.DOTALL)

        if match:
            return match.group(1).strip()

        # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œè¿”å›å…¨éƒ¨å†…å®¹
        logger.warning("LLMå“åº”ä¸­æœªæ‰¾åˆ°ä»£ç å—æ ‡è®°ï¼Œè¿”å›å…¨éƒ¨å†…å®¹")
        return content.strip()

    def switch_model(self, model_name: str):
        """åˆ‡æ¢æ¨¡å‹

        Args:
            model_name: æ–°æ¨¡å‹åç§°
        """
        self.model_name = model_name
        self.model_config = self.config.get_model_config(model_name)
        logger.info(f"åˆ‡æ¢æ¨¡å‹: {model_name}")

    def _chat_stream(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None
    ):
        """æµå¼èŠå¤©è¯·æ±‚ï¼ˆç”Ÿæˆå™¨ï¼‰

        Yields:
            æµå¼å“åº”å—ï¼ŒåŒ…å«deltaå†…å®¹
        """
        import json

        # æ„å»ºè¯·æ±‚ä½“
        # Claude(Bedrock)é€‚é…ï¼šä¸å…è®¸ç©ºcontentï¼›æœ€å°åŒ–å…¼å®¹ï¼ˆä»ä½¿ç”¨OAIæ ·å¼ï¼Œç”±ç½‘å…³è½¬æ¢ï¼‰
        def _sanitize_msgs_for_claude(msgs: List[Dict[str, Any]]):
            out = []
            for m in msgs:
                c = m.get("content")
                if isinstance(c, str) and (c.strip() == "" or c is None):
                    m = dict(m)
                    m["content"] = "â€¦"
                out.append(m)
            return out

        used_messages = messages
        used_tools = tools
        is_claude = self._is_claude()
        is_gemini = self._is_gemini()

        if is_claude:
            used_messages = _sanitize_msgs_for_claude(messages)
            # æ¸…ç†å­¤ç«‹çš„toolæ¶ˆæ¯ï¼ˆBedrockåç«¯ä¸¥æ ¼è¦æ±‚ï¼‰
            used_messages = self._remove_orphaned_tool_messages(used_messages)
            # æ¸…ç†inf/nanå€¼
            used_messages = self._sanitize_inf_values(used_messages)

        # ===== GeminiåŸç”ŸAPI =====
        if is_gemini:
            # ä»base_urlä¸­æå–ä¸»æœºåï¼Œæ„å»ºGeminiåŸç”ŸAPIç«¯ç‚¹
            import urllib.parse
            parsed = urllib.parse.urlparse(self.model_config['base_url'])
            gemini_url = f"{parsed.scheme}://{parsed.netloc}/v1/models/{self.model_name}"
            headers_gemini = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.model_config['api_key']}"
            }

            # æ„å»ºGeminiæ ¼å¼payload
            gemini_contents = self._convert_messages_to_contents(messages)

            # è°ƒè¯•: æ‰“å°åŸå§‹toolså‚æ•°
            logger.info(f"[Gemini Debug] æ¥æ”¶åˆ°çš„toolså‚æ•°: {tools is not None}, æ•°é‡: {len(tools) if tools else 0}")

            gemini_tools = self._convert_tools_to_gemini(tools)

            # è°ƒè¯•: æ‰“å°è½¬æ¢åçš„gemini_tools
            logger.info(f"[Gemini Debug] è½¬æ¢åçš„gemini_tools: {gemini_tools is not None}, å†…å®¹: {gemini_tools if gemini_tools else 'None'}")

            payload_gemini = {
                "contents": gemini_contents
            }
            if gemini_tools:
                payload_gemini["tools"] = gemini_tools
                logger.info(f"[Gemini Debug] toolså­—æ®µå·²æ·»åŠ åˆ°payload")
            else:
                logger.warning(f"[Gemini Debug] gemini_toolsä¸ºç©º,æœªæ·»åŠ toolså­—æ®µåˆ°payload")
            if temperature is not None:
                payload_gemini["generationConfig"] = {"temperature": temperature}
            if max_tokens:
                payload_gemini["generationConfig"] = payload_gemini.get("generationConfig", {})
                payload_gemini["generationConfig"]["maxOutputTokens"] = max_tokens

            logger.info(f"[Gemini] ä½¿ç”¨åŸç”ŸAPI: {gemini_url}")
            logger.info(f"[Gemini] Payload: {json.dumps(payload_gemini, ensure_ascii=False)}")

            try:
                response = requests.post(
                    gemini_url,
                    headers=headers_gemini,
                    json=payload_gemini,
                    timeout=self.model_config["timeout"]
                )
                if response.status_code >= 400:
                    try:
                        error_detail = response.json()
                        logger.error(f"[Gemini] è¯·æ±‚å¤±è´¥è¯¦æƒ…: status={response.status_code}, error={json.dumps(error_detail, ensure_ascii=False)}")
                    except:
                        logger.error(f"[Gemini] è¯·æ±‚å¤±è´¥è¯¦æƒ…: status={response.status_code}, text={response.text[:500]}")
                response.raise_for_status()
                gemini_response = response.json()

                logger.info(f"[Gemini] å“åº”: {json.dumps(gemini_response, ensure_ascii=False)[:500]}")

                # è§£æGeminiå“åº”
                full_content = ""
                tool_calls_list = []
                gemini_parts_with_tool_calls = []  # ä¿å­˜åŒ…å«functionCallçš„åŸå§‹parts

                candidates = gemini_response.get("candidates", [])
                if candidates:
                    candidate = candidates[0]
                    content_data = candidate.get("content", {})
                    parts = content_data.get("parts", [])

                    for part in parts:
                        # è°ƒè¯•ï¼šè®°å½•æ¯ä¸ªpartçš„ç»“æ„ï¼ˆç”¨äºå‘ç°æ–°çš„æ€è€ƒå­—æ®µï¼‰
                        logger.debug(f"[Gemini] Part keys: {list(part.keys())}")

                        # æ€è€ƒè¿‡ç¨‹ï¼ˆGemini 2.0 Flash Thinkingï¼‰
                        # Geminiå°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨å•ç‹¬çš„partä¸­ï¼Œæ£€æŸ¥å¤šç§å¯èƒ½çš„å­—æ®µå
                        thought_text = None
                        if "thought" in part:
                            thought_text = part.get("thought")
                        elif "thoughtText" in part:
                            thought_text = part.get("thoughtText")
                        elif "thinking" in part:
                            thought_text = part.get("thinking")

                        if thought_text:
                            logger.info(f"[Gemini] å‘ç°æ€è€ƒè¿‡ç¨‹: {len(thought_text)} å­—ç¬¦")
                            yield {"type": "reasoning", "delta": thought_text, "full_reasoning": thought_text}

                        # æ–‡æœ¬å†…å®¹
                        if "text" in part:
                            text = part["text"]
                            full_content += text
                            yield {"type": "content", "delta": text, "full_content": full_content}

                        # Function call
                        if "functionCall" in part:
                            # ä¿å­˜åŸå§‹partï¼ˆåŒ…å«thoughtSignatureç­‰æ‰€æœ‰å­—æ®µï¼‰
                            gemini_parts_with_tool_calls.append(part)

                            fc = part["functionCall"]
                            tool_call_id = f"call_{int(time.time()*1000)}_{len(tool_calls_list)}"
                            tool_calls_list.append({
                                "id": tool_call_id,
                                "type": "function",
                                "function": {
                                    "name": fc.get("name", ""),
                                    "arguments": json.dumps(fc.get("args", {}), ensure_ascii=False)
                                }
                            })

                # æ„å»ºæœ€ç»ˆå“åº”
                final_response = {
                    "content": full_content or None,
                    "model": self.model_name,
                    "usage": gemini_response.get("usageMetadata", {}),
                    "raw_response": gemini_response
                }

                if tool_calls_list:
                    final_response["tool_calls"] = tool_calls_list
                    # ä¿å­˜GeminiåŸç”Ÿpartsä¾›ä¸‹ä¸€è½®ä½¿ç”¨
                    final_response["_gemini_original_parts"] = gemini_parts_with_tool_calls

                yield {"type": "done", "response": final_response}
                return

            except Exception as e:
                logger.error(f"[Gemini] è¯·æ±‚å¤±è´¥: {e}")
                # Geminiå¤±è´¥ä¸fallbackï¼Œç›´æ¥æŠ›å‡º
                raise

        # ä¼˜å…ˆå°è¯•ClaudeåŸç”Ÿmessagesåè®®
        if is_claude and getattr(self.config, 'claude_force_native', True):
            native_url = self._build_claude_native_url()
            headers_native = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.model_config['api_key']}",
                "anthropic-version": "2023-06-01"
            }
            # ä½¿ç”¨æ¸…ç†è¿‡çš„messagesï¼ˆåŒ…å«inf/nanæ¸…ç†å’Œå­¤ç«‹toolæ¶ˆæ¯ç§»é™¤ï¼‰
            payload_native = self._build_anthropic_messages_payload(used_messages, tools, temperature, max_tokens)
            payload_native["stream"] = True

            # æ¸…ç†inf/nanå€¼ï¼ˆJSONä¸æ”¯æŒï¼‰
            payload_native = self._sanitize_inf_values(payload_native)

            try:
                response = requests.post(
                    native_url,
                    headers=headers_native,
                    json=payload_native,
                    timeout=self.model_config["timeout"],
                    stream=True
                )
                if response.status_code < 400:
                    # è§£æAnthropicæµå¼
                    full_content = ""
                    tool_uses: Dict[str, Dict[str, Any]] = {}
                    last_tool_id: Optional[str] = None
                    for raw in response.iter_lines():
                        if not raw:
                            continue
                        line = raw.decode('utf-8', errors='ignore')
                        if not line.startswith('data: '):
                            continue
                        data_str = line[6:]
                        if not data_str.strip() or data_str.strip() == "[DONE]":
                            continue
                        try:
                            evt = json.loads(data_str)
                        except Exception:
                            continue

                        et = evt.get("type")
                        # å…³é”®è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰äº‹ä»¶
                        logger.info(f"[Claudeæµå¼äº‹ä»¶] type={et}, event={json.dumps(evt, ensure_ascii=False)[:300]}")

                        if et == "content_block_start":
                            block = evt.get("content_block", {})
                            if block.get("type") == "tool_use":
                                tid = block.get("id") or f"tu_{int(time.time()*1000)}"
                                tool_uses[tid] = {"name": block.get("name", ""), "input_str": "", "input": block.get("input")}
                                last_tool_id = tid
                                logger.debug(f"æµå¼tool_useå¼€å§‹: id={tid}, name={block.get('name')}, input={block.get('input')}")
                        elif et == "content_block_delta":
                            delta = evt.get("delta", {})
                            delta_type = delta.get("type")
                            logger.debug(f"æµå¼delta: type={delta_type}, keys={list(delta.keys())}")
                            if delta_type == "text_delta":
                                text = delta.get("text", "")
                                if text:
                                    full_content += text
                                    yield {"type": "content", "delta": text, "full_content": full_content}
                            elif delta_type == "input_json_delta":
                                # Claudeæµå¼tool_useçš„æ­£ç¡®ç±»å‹æ˜¯input_json_deltaï¼Œä¸æ˜¯å…¶ä»–
                                partial = delta.get("partial_json")
                                if partial and last_tool_id and last_tool_id in tool_uses:
                                    tool_uses[last_tool_id]["input_str"] += partial
                                    logger.debug(f"ç´¯ç§¯tool input: {len(tool_uses[last_tool_id]['input_str'])} å­—ç¬¦")
                            else:
                                # æ—§é€»è¾‘å…¼å®¹ï¼šå¦‚æœä¸æ˜¯text_deltaï¼Œå°è¯•æå–partial_json
                                partial = delta.get("partial_json")
                                if partial and last_tool_id and last_tool_id in tool_uses:
                                    tool_uses[last_tool_id]["input_str"] += partial
                                    logger.debug(f"ç´¯ç§¯tool input(fallback): {len(tool_uses[last_tool_id]['input_str'])} å­—ç¬¦")
                        elif et == "content_block_stop":
                            if last_tool_id and last_tool_id in tool_uses:
                                info = tool_uses[last_tool_id]
                                if info.get("input") is None and info.get("input_str"):
                                    try:
                                        info["input"] = json.loads(info["input_str"]) or {}
                                    except Exception:
                                        info["input"] = {}
                            last_tool_id = None
                        elif et == "message_stop":
                            break
                        else:
                            # å…¶å®ƒäº‹ä»¶å¿½ç•¥ï¼ˆmessage_start, ping, ...ï¼‰
                            pass

                    final_response = {
                        "content": full_content or None,
                        "model": self.model_name,
                        "usage": {},
                        "raw_response": {}
                    }
                    tool_calls = []
                    for tid, info in tool_uses.items():
                        name = info.get("name") or ""
                        args_obj = info.get("input")
                        input_str = info.get("input_str") or ""

                        logger.info(f"æµå¼tool_useå®Œæˆ: id={tid}, name={name}, input={args_obj}, input_str_len={len(input_str)}")

                        # ä¿®å¤ï¼šå¦‚æœinputä¸ºç©ºæˆ–Noneï¼Œå°è¯•ä»input_strè§£æ
                        if not args_obj or args_obj is None:
                            s = input_str
                            try:
                                args_obj = json.loads(s) if s else {}
                                logger.info(f"ä»input_strè§£æå‚æ•°æˆåŠŸ: {len(str(args_obj))} å­—ç¬¦")
                            except Exception as e:
                                logger.error(f"ä»input_strè§£æå‚æ•°å¤±è´¥: {e}, input_str={s[:200]}")
                                args_obj = {}
                        tool_calls.append({
                            "id": tid,
                            "type": "function",
                            "function": {"name": name, "arguments": json.dumps(args_obj, ensure_ascii=False)}
                        })
                    if tool_calls:
                        final_response["tool_calls"] = tool_calls
                    yield {"type": "done", "response": final_response}
                    return
                else:
                    # Claude native APIè¿”å›é200ï¼Œç›´æ¥æŠ¥é”™ï¼ˆä¸å†fallbackï¼‰
                    error_msg = f"ClaudeåŸç”ŸAPIå¤±è´¥: status={response.status_code}"
                    try:
                        error_detail = response.json()
                        error_msg += f", detail={error_detail}"
                    except:
                        error_msg += f", text={response.text[:500]}"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg)
            except Exception as e:
                # Claude native APIå¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡ºï¼ˆä¸å†fallbackï¼‰
                logger.error(f"ClaudeåŸç”Ÿmessagesè¯·æ±‚å¤±è´¥: {e}")
                raise

        # â€”â€” OAI ChatCompletions å¸¸è§„æµå¼ â€”â€”
        payload = {
            "model": self.model_config["model"],
            "messages": used_messages,
            "temperature": temperature,
            "stream": True
        }
        if max_tokens:
            payload["max_tokens"] = max_tokens

        # Reasoning effortå‚æ•°ï¼ˆä»…OpenAIæ¨¡å‹æ”¯æŒï¼‰
        if not is_claude:
            payload["reasoning_effort"] = "high"

        if used_tools:
            payload["tools"] = used_tools
            if tool_choice:
                payload["tool_choice"] = tool_choice
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.model_config['api_key']}"
        }
        if is_claude:
            headers["anthropic-version"] = headers.get("anthropic-version", "2023-06-01")

        # è®°å½•è¯·æ±‚æ—¥å¿—ï¼ˆè„±æ•ï¼‰
        if self.config.agent_enable_request_logging:
            try:
                msg_preview = []
                for m in (used_messages or []):
                    role = m.get("role")
                    content = m.get("content", "")

                    # è¯¦ç»†è®°å½•multimodalæ¶ˆæ¯ç»“æ„
                    if isinstance(content, list):
                        # Multimodalæ¶ˆæ¯ï¼šè®°å½•æ¯ä¸ªpartçš„ç±»å‹å’Œå¤§å°
                        parts_info = []
                        for part in content:
                            if isinstance(part, dict):
                                part_type = part.get("type")
                                if part_type == "text":
                                    text_len = len(part.get("text", ""))
                                    parts_info.append(f"text({text_len}chars)")
                                elif part_type == "image_url":
                                    image_url = part.get("image_url", {}).get("url", "")
                                    if image_url.startswith("data:"):
                                        # æå–mime typeå’Œbase64é•¿åº¦
                                        try:
                                            header, base64_data = image_url.split(",", 1)
                                            mime = header.split(":")[1].split(";")[0]
                                            base64_len = len(base64_data)
                                            parts_info.append(f"image({mime},{base64_len}chars_base64)")
                                        except:
                                            parts_info.append("image(unknown)")
                                    else:
                                        parts_info.append(f"image({image_url[:50]}...)")
                        msg_preview.append({"role": role, "content": parts_info})
                    elif isinstance(content, str):
                        msg_preview.append({"role": role, "content_len": len(content)})
                    else:
                        msg_preview.append({"role": role, "content_type": type(content).__name__})

                logger.debug(
                    f"LLMæµå¼è¯·æ±‚: model={self.model_name}, stream=True, messages={msg_preview}, tools={len(tools) if tools else 0}, tool_choice={tool_choice}"
                )
            except Exception as e:
                logger.warning(f"è®°å½•è¯·æ±‚æ—¥å¿—å¤±è´¥: {e}")

        last_error = None
        for attempt in range(1, self.max_retries + 1):
            try:
                # å‘é€æµå¼è¯·æ±‚
                response = requests.post(
                    self.model_config["base_url"],
                    headers=headers,
                    json=payload,
                    timeout=self.model_config["timeout"],
                    stream=True
                )
                if response.status_code >= 400:
                    detail = None
                    try:
                        detail = response.text[:500]
                    except Exception:
                        detail = None
                    logger.error(
                        f"LLMæµå¼è¯·æ±‚å¤±è´¥: status={response.status_code}, detail={detail}"
                    )
                    if 400 <= response.status_code < 500 and response.status_code != 429:
                        response.raise_for_status()
                response.raise_for_status()

                # ç´¯ç§¯å®Œæ•´å“åº”ç”¨äºæœ€ç»ˆè¿”å›
                full_content = ""
                full_reasoning = ""
                full_tool_calls = []
                current_tool_call = None

                # é€å—å¤„ç†SSEæµ
                for line in response.iter_lines():
                    if not line:
                        continue

                    line = line.decode('utf-8')

                    # SSEæ ¼å¼ï¼šdata: {...}
                    if line.startswith('data: '):
                        data_str = line[6:]  # ç§»é™¤ "data: " å‰ç¼€

                        # æ£€æŸ¥æ˜¯å¦ä¸ºæµç»“æŸæ ‡è®°
                        if data_str.strip() == '[DONE]':
                            break

                        try:
                            chunk = json.loads(data_str)

                            # è®°å½•åŸå§‹chunkç”¨äºè°ƒè¯•
                            logger.debug(f"åŸå§‹chunk: {json.dumps(chunk, ensure_ascii=False)[:500]}")

                            if "choices" in chunk and len(chunk["choices"]) > 0:
                                delta = chunk["choices"][0].get("delta", {})

                                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹deltaä¸­çš„æ‰€æœ‰å­—æ®µ
                                if delta:
                                    logger.info(f"[Thinking Debug] Delta keys: {list(delta.keys())}, model={self.model_name}")
                                    # æ‰“å°å¯èƒ½çš„thinkingç›¸å…³å­—æ®µ
                                    for key in ["reasoning", "reasoning_content", "thoughts", "thinking", "internal_thoughts"]:
                                        if key in delta:
                                            logger.info(f"[Thinking Debug] Found {key}: {delta[key][:100] if delta[key] else '(empty)'}")

                                # å¤„ç†reasoningå­—æ®µï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
                                # å…¼å®¹å¤šç§åè®®ï¼šreasoningï¼ˆERNIE-5ç­‰ï¼‰ã€reasoning_contentï¼ˆOpenAI Oç³»åˆ—ã€Deepseekç­‰ï¼‰
                                reasoning_delta = delta.get("reasoning") or delta.get("reasoning_content")
                                if reasoning_delta:
                                    full_reasoning += reasoning_delta

                                    # yieldæ€è€ƒè¿‡ç¨‹å¢é‡
                                    yield {
                                        "type": "reasoning",
                                        "delta": reasoning_delta,
                                        "full_reasoning": full_reasoning
                                    }

                                # å¤„ç†å†…å®¹å¢é‡
                                if "content" in delta and delta["content"]:
                                    content_delta = delta["content"]
                                    full_content += content_delta

                                    # yieldå†…å®¹å¢é‡
                                    yield {
                                        "type": "content",
                                        "delta": content_delta,
                                        "full_content": full_content
                                    }

                                # å¤„ç†tool_callså¢é‡
                                if "tool_calls" in delta:
                                    # ğŸ” GLM-4.7è°ƒè¯•ï¼šè®°å½•æ¯ä¸ªtool_call delta
                                    if self.model_name == "glm-4.7":
                                        logger.info(f"[GLM-4.7 Debug] tool_calls delta: {json.dumps(delta['tool_calls'], ensure_ascii=False)}")

                                    for tc_delta in delta["tool_calls"]:
                                        index = tc_delta.get("index", 0)

                                        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„tool_callæ§½ä½
                                        while len(full_tool_calls) <= index:
                                            full_tool_calls.append({
                                                "id": "",
                                                "type": "function",
                                                "function": {"name": "", "arguments": ""}
                                            })

                                        # æ›´æ–°tool_call
                                        if "id" in tc_delta:
                                            full_tool_calls[index]["id"] = tc_delta["id"]
                                        if "function" in tc_delta:
                                            if "name" in tc_delta["function"]:
                                                full_tool_calls[index]["function"]["name"] = tc_delta["function"]["name"]
                                            if "arguments" in tc_delta["function"]:
                                                full_tool_calls[index]["function"]["arguments"] += tc_delta["function"]["arguments"]

                        except json.JSONDecodeError:
                            logger.warning(f"æ— æ³•è§£ææµå¼å“åº”å—: {data_str}")
                            continue

                # æµç»“æŸåè¿”å›å®Œæ•´å“åº”
                final_response = {
                    "content": full_content if full_content else None,
                    "model": self.model_name,
                    "usage": {},
                    "raw_response": {}
                }
                if full_tool_calls:
                    final_response["tool_calls"] = full_tool_calls
                yield {"type": "done", "response": final_response}
                return

            except (requests.exceptions.Timeout, requests.exceptions.RequestException) as e:
                last_error = e
                try:
                    status = getattr(e.response, "status_code", None)
                except Exception:
                    status = None

                # å°è¯•è§£æé”™è¯¯å“åº”ä½“ï¼Œæå–è¯¦ç»†é”™è¯¯ä¿¡æ¯
                error_detail = None
                error_type = None
                user_friendly_message = None

                if hasattr(e, 'response') and e.response is not None:
                    try:
                        response_text = e.response.text
                        error_data = json.loads(response_text)

                        # Azure OpenAIé”™è¯¯æ ¼å¼: {"error": {"message": "...", "code": "..."}}
                        if isinstance(error_data, dict) and "error" in error_data:
                            error_obj = error_data["error"]
                            error_detail = error_obj.get("message", "")
                            error_code = error_obj.get("code", "")

                            # è¯†åˆ«content_filteré”™è¯¯
                            if "content" in error_detail.lower() and ("filter" in error_detail.lower() or "policy" in error_detail.lower() or "management" in error_detail.lower()):
                                error_type = "content_filter"
                                user_friendly_message = "æ‚¨çš„è¯·æ±‚è§¦å‘äº†å†…å®¹å®‰å…¨ç­–ç•¥ï¼Œè¯·ä¿®æ”¹åé‡è¯•ã€‚å¦‚æœæ‚¨è®¤ä¸ºè¿™æ˜¯è¯¯åˆ¤ï¼Œè¯·å°è¯•æ¢ä¸€ç§è¡¨è¾¾æ–¹å¼ã€‚"
                            # è¯†åˆ«deploymentè¢«å°ç¦ï¼ˆé€šå¸¸æ˜¯content_filterçš„å‰¯ä½œç”¨ï¼‰
                            elif "deployment" in error_detail.lower() and ("not exist" in error_detail.lower() or "not found" in error_detail.lower()):
                                error_type = "deployment_blocked"
                                user_friendly_message = "âš ï¸ APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n\nå¯èƒ½åŸå› ï¼š\nâ€¢ ä¹‹å‰çš„è¯·æ±‚è§¦å‘äº†å†…å®¹å®¡æ ¸ï¼ŒAPIå·²è¢«ä¸´æ—¶å°ç¦\nâ€¢ æœåŠ¡æ­£åœ¨ç»´æŠ¤æˆ–é‡å¯\n\nå»ºè®®ï¼š\n1. ç­‰å¾…5-10åˆ†é’Ÿåé‡è¯•\n2. åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹ï¼ˆå¦‚GPT/Claudeï¼‰\n3. ç®€åŒ–é—®é¢˜æè¿°ï¼Œé¿å…æ•æ„Ÿå†…å®¹"
                            # è¯†åˆ«é…é¢é”™è¯¯
                            elif "quota" in error_detail.lower() or "insufficient" in error_detail.lower():
                                error_type = "quota_exceeded"
                                user_friendly_message = "APIé…é¢å·²ç”¨å°½ï¼Œè¯·è”ç³»ç®¡ç†å‘˜"
                            # è¯†åˆ«å‚æ•°é”™è¯¯
                            elif "invalid" in error_detail.lower() or "parameter" in error_detail.lower():
                                error_type = "invalid_parameter"
                                user_friendly_message = "è¯·æ±‚å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹"
                            else:
                                # å…¶ä»–4xxé”™è¯¯ï¼Œä½¿ç”¨åŸå§‹é”™è¯¯æ¶ˆæ¯ï¼ˆæˆªæ–­ï¼‰
                                user_friendly_message = error_detail[:200] if len(error_detail) > 200 else error_detail
                    except Exception as parse_error:
                        logger.debug(f"æ— æ³•è§£æé”™è¯¯å“åº”ä½“: {parse_error}")

                # å¯è¯»çš„å¤±è´¥åŸå› ï¼ˆä¸æš´éœ²æ•æ„Ÿä¿¡æ¯ï¼‰
                reason = "è¯·æ±‚å¤±è´¥"
                if isinstance(e, requests.exceptions.Timeout):
                    reason = "è¶…æ—¶"
                elif status == 429:
                    reason = "é€Ÿç‡é™åˆ¶"
                elif status is not None and status >= 500:
                    reason = "æœåŠ¡å¼‚å¸¸"
                elif status is not None and 400 <= status < 500:
                    if error_type:
                        reason = error_type
                    else:
                        reason = "å®¢æˆ·ç«¯é”™è¯¯"
                else:
                    reason = "ç½‘ç»œå¼‚å¸¸"

                # 4xx(é429)é”™è¯¯å¤„ç†ï¼šåŒºåˆ†å¯æ¢å¤é”™è¯¯å’Œä¸å¯æ¢å¤é”™è¯¯
                if status is not None and 400 <= status < 500 and status != 429:
                    logger.error(f"LLMæµå¼è¯·æ±‚å¤±è´¥(4xx,ä¸é‡è¯•): {e}, error_type={error_type}, detail={error_detail[:200] if error_detail else None}")

                    # content_filteré”™è¯¯ï¼šAgentå¯ä»¥è°ƒæ•´ç­–ç•¥ï¼Œä¼˜é›…æ¢å¤
                    if error_type == "content_filter":
                        logger.info("æ£€æµ‹åˆ°content_filteré”™è¯¯ï¼Œå°†ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯è¿”å›ç»™Agentï¼Œè®©å…¶è°ƒæ•´ç­–ç•¥")

                        # è¿”å›ç³»ç»Ÿæç¤ºç»™Agentï¼ˆä¸æš´éœ²ç»™ç”¨æˆ·ï¼‰
                        system_message = (
                            "[ç³»ç»Ÿæç¤º] æ‚¨çš„ä¸Šä¸€æ¬¡å›å¤è§¦å‘äº†å†…å®¹å®‰å…¨ç­–ç•¥ã€‚"
                            "è¯·è°ƒæ•´è¡¨è¾¾æ–¹å¼ï¼Œé¿å…æ•æ„Ÿå†…å®¹ï¼Œç„¶åé‡æ–°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                        )

                        yield {
                            "type": "done",
                            "response": {
                                "role": "assistant",
                                "content": system_message,
                                "finish_reason": "content_filter"
                            }
                        }
                        return  # ä¸raiseï¼Œè®©Agentç»§ç»­å¾ªç¯

                    # å…¶ä»–4xxé”™è¯¯ï¼šAgentæ— æ³•è‡ªå·±è§£å†³ï¼Œç»ˆæ­¢æµç¨‹
                    else:
                        final_message = user_friendly_message if user_friendly_message else f"LLMè¯·æ±‚å¤±è´¥({reason})"

                        yield {
                            "type": "error",
                            "message": final_message,
                            "status_code": status,
                            "error_type": error_type
                        }
                        raise

                if attempt >= self.max_retries:
                    logger.error(f"LLMæµå¼è¯·æ±‚å¤±è´¥ä¸”é‡è¯•è€—å°½({attempt}/{self.max_retries}): {e}")
                    yield {"type": "retry_exhausted", "attempt": attempt, "max_retries": self.max_retries, "reason": reason}
                    raise

                # é’ˆå¯¹429é€Ÿç‡é™åˆ¶ä½¿ç”¨æ›´æ¿€è¿›çš„é€€é¿ç­–ç•¥
                if status == 429:
                    # 429é”™è¯¯ï¼šä½¿ç”¨æ›´é•¿çš„æŒ‡æ•°é€€é¿ï¼Œä»2ç§’å¼€å§‹
                    delay = 2.0 * (2 ** (attempt - 1))  # 2s, 4s, 8s, 16s, 32s
                    delay += random.uniform(0, 1.0)  # æ·»åŠ æŠ–åŠ¨é¿å…é›·é¸£ç¾¤æ•ˆåº”
                    logger.warning(f"é‡åˆ°é€Ÿç‡é™åˆ¶(429)ï¼Œä½¿ç”¨é•¿é€€é¿ç­–ç•¥ï¼Œé‡è¯•ç¬¬{attempt}/{self.max_retries}æ¬¡ï¼Œç­‰å¾…{delay:.2f}s: {e}")
                else:
                    # å…¶ä»–é”™è¯¯ï¼šä½¿ç”¨æ ‡å‡†æŒ‡æ•°é€€é¿
                    delay = self.retry_base_delay * (2 ** (attempt - 1))
                    delay += random.uniform(0, self.retry_base_delay)
                    logger.warning(f"LLMæµå¼è¯·æ±‚å¤±è´¥ï¼Œé‡è¯•ç¬¬{attempt}/{self.max_retries}æ¬¡åé‡è¿ï¼Œç­‰å¾…{delay:.2f}s: {e}")

                # å°†é‡è¯•è®¡åˆ’å‘ŠçŸ¥ä¸Šå±‚ï¼ˆä¾›å‰ç«¯å±•ç¤ºï¼‰ï¼Œä¸åŒ…å«URLç­‰æ•æ„Ÿä¿¡æ¯
                yield {"type": "retry", "attempt": attempt, "max_retries": self.max_retries, "delay": round(delay, 2), "reason": reason}
                time.sleep(delay)
