# CreativeFlow 技术方案设计

## 文档概述

本文档定义CreativeFlow的完整技术实现方案,包括:技术架构、技术栈选型、核心模块设计、部署方案、开发路线图。

---

## 1. 整体技术架构

### 1.1 系统架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        用户交互层                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Web UI (Gradio/Streamlit)          CLI (Typer)                │
│  • 对话式交互                        • 命令行工具               │
│  • 文件上传/下载                     • 脚本集成                 │
│  • 进度可视化                        • Pipeline调用             │
│                                                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │ HTTP API / Python SDK
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Master Agent 核心层                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  Intent Router (意图路由)                                │  │
│  │  • 用户意图识别 (LLM)                                    │  │
│  │  • 场景匹配 (Workflow vs Atomic)                        │  │
│  │  • 参数提取                                              │  │
│  └──────────────────────────────────────────────────────────┘  │
│                         │                                       │
│                         ▼                                       │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  Execution Orchestrator (执行编排器)                     │  │
│  │  • Workflow Tool调度                                     │  │
│  │  • Atomic Tool组合                                       │  │
│  │  • 异常处理与重试                                        │  │
│  │  • 进度追踪与反馈                                        │  │
│  └──────────────────────────────────────────────────────────┘  │
│                         │                                       │
│                         ▼                                       │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  Conversation Manager (对话管理)                         │  │
│  │  • 多轮对话上下文                                        │  │
│  │  • 用户确认与反馈                                        │  │
│  │  • 会话状态管理                                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│ Workflow     │  │ Atomic       │  │ LLM          │
│ Tools        │  │ Tools        │  │ Services     │
└──────────────┘  └──────────────┘  └──────────────┘
        │                │                │
        └────────────────┴────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                      工具执行层                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌────────────────┐  ┌────────────────┐  ┌─────────────────┐  │
│  │ Workflow Tools │  │ Atomic Tools   │  │ LLM Engines     │  │
│  ├────────────────┤  ├────────────────┤  ├─────────────────┤  │
│  │                │  │                │  │                 │  │
│  │• UGC分析       │  │• Web Scraper   │  │• GPT-4o         │  │
│  │  工作流        │  │  (Scrapy)      │  │• Claude 3.5     │  │
│  │                │  │                │  │• 文心4.0        │  │
│  │• 活动策划      │  │• Vision        │  │                 │  │
│  │  工作流        │  │  Service       │  │• Code Gen       │  │
│  │                │  │  (CLIP/YOLO)   │  │  (Copilot)      │  │
│  │• 数据报告      │  │                │  │                 │  │
│  │  工作流        │  │• Code          │  │• Text Gen       │  │
│  │                │  │  Executor      │  │  (Direct LLM)   │  │
│  │                │  │  (Sandbox)     │  │                 │  │
│  │                │  │                │  │                 │  │
│  └────────────────┘  └────────────────┘  └─────────────────┘  │
│                                                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                      基础设施层                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌────────────┐  ┌────────────┐  ┌────────────┐  ┌──────────┐ │
│  │ 数据存储    │  │ 任务队列    │  │ 缓存       │  │ 监控     │ │
│  ├────────────┤  ├────────────┤  ├────────────┤  ├──────────┤ │
│  │            │  │            │  │            │  │          │ │
│  │• PostgreSQL│  │• Celery    │  │• Redis     │  │• Logging │ │
│  │  (元数据)  │  │  (异步任务)│  │  (会话)    │  │          │ │
│  │            │  │            │  │            │  │• Metrics │ │
│  │• MinIO/S3  │  │• RabbitMQ  │  │            │  │  (Prom)  │ │
│  │  (文件)    │  │            │  │            │  │          │ │
│  │            │  │            │  │            │  │• Trace   │ │
│  │            │  │            │  │            │  │          │ │
│  └────────────┘  └────────────┘  └────────────┘  └──────────┘ │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 架构设计原则

**1. 分层解耦**
- 用户交互层 ↔ Master Agent层 ↔ 工具执行层 ↔ 基础设施层
- 每层独立演进,便于测试和替换

**2. 可扩展性**
- Workflow Tool和Atomic Tool采用插件化设计
- 新增工具无需修改Master Agent核心代码
- 支持水平扩展(多Worker并发执行)

**3. 容错性**
- 异步任务支持重试机制
- 长时间任务支持断点续传
- 非关键步骤失败降级处理

**4. 可观测性**
- 完整的日志记录(用户请求→工具调用→结果返回)
- 性能指标监控(耗时、成功率、资源占用)
- 分布式追踪(跨服务调用链路)

---

## 2. 技术栈选型

### 2.1 核心技术栈

| 层级 | 组件 | 技术选型 | 选型理由 |
|------|------|---------|---------|
| **用户交互层** | Web UI | Gradio | 快速原型,内置聊天界面 |
| | CLI | Typer | 类型安全,自动生成帮助 |
| **Master Agent** | 框架 | LangGraph | 状态机管理,支持复杂流程 |
| | LLM SDK | LiteLLM | 统一接口,支持多模型切换 |
| **工具执行层** | Web Search | Tavily API (主) + Serper API (备) | LLM-ready输出,免费额度高 |
| | URL Fetch | Jina Reader (主) + Firecrawl (备) | 免费、简单、高质量 |
| | Web抓取 | Scrapy + Playwright | 反爬能力强,支持JS渲染 |
| | Vision | Transformers (CLIP) | 开源可控,性能好 |
| | 代码执行 | Docker Sandbox | 安全隔离,支持多语言 |
| **基础设施** | 数据库 | PostgreSQL | 成熟稳定,支持JSON |
| | 对象存储 | MinIO | S3兼容,可自部署 |
| | 任务队列 | Celery + Redis | Python生态成熟 |
| | 监控 | Prometheus + Grafana | 开源标准方案 |
| **开发工具** | 语言 | Python 3.11+ | Agent开发主流语言 |
| | 包管理 | Poetry | 依赖管理清晰 |
| | 代码质量 | Ruff + MyPy | 快速Linter + 类型检查 |

### 2.2 LLM模型选型

**分层使用策略**:

| 场景 | 模型选择 | 成本 | 原因 |
|------|---------|------|------|
| **Master Agent意图识别** | GPT-4o-mini | ¥0.001/1k tokens | 简单任务,追求速度 |
| **Workflow内LLM直接处理** | Claude 3.5 Sonnet | ¥0.015/1k tokens | 复杂分析,质量优先 |
| **代码生成** | GPT-4o | ¥0.015/1k tokens | 代码质量好 |
| **文本生成(文案)** | 文心4.0 | ¥0.008/1k tokens | 中文效果好,成本低 |

**模型切换机制**:
- 使用LiteLLM统一接口
- 配置文件定义场景→模型映射
- 支持Fallback(主模型失败切换备用)

---

## 3. 核心模块设计

### 3.1 Master Agent实现方案

**技术选型: LangGraph**

**为什么选LangGraph而非LangChain?**

| 对比项 | LangChain | LangGraph | 选择 |
|--------|-----------|-----------|------|
| **状态管理** | 基于链式调用,状态隐式 | 显式状态图,易调试 | ✅ LangGraph |
| **复杂流程** | 难以处理条件分支/循环 | 原生支持图结构 | ✅ LangGraph |
| **人工介入** | 需额外封装 | 内置Human-in-the-loop | ✅ LangGraph |
| **可观测性** | 日志分散 | 状态可视化 | ✅ LangGraph |
| **学习成本** | 中等 | 稍高(需理解状态图) | - |

**LangGraph架构设计**:

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Literal

# 定义状态
class AgentState(TypedDict):
    user_input: str
    intent: dict
    matched_workflow: str | None
    execution_plan: list
    tool_results: list
    conversation_history: list
    final_output: dict | None
    error: str | None

# 定义节点
def intent_analysis_node(state: AgentState) -> AgentState:
    """意图识别节点"""
    llm_response = call_llm_mini(
        prompt=f"分析用户意图: {state['user_input']}"
    )
    state["intent"] = parse_intent(llm_response)
    return state

def workflow_matching_node(state: AgentState) -> AgentState:
    """Workflow匹配节点"""
    intent = state["intent"]

    # 匹配预定义Workflow
    if intent["type"] == "UGC分析":
        state["matched_workflow"] = "ugc_analysis_workflow"
    elif intent["type"] == "活动策划":
        state["matched_workflow"] = "campaign_planning_workflow"
    else:
        state["matched_workflow"] = None
        # 生成Atomic Tools组合计划
        state["execution_plan"] = plan_atomic_tools(intent)

    return state

def workflow_execution_node(state: AgentState) -> AgentState:
    """执行Workflow Tool"""
    workflow_name = state["matched_workflow"]
    workflow = get_workflow_tool(workflow_name)

    # 执行workflow(内部有进度回调)
    result = workflow.execute(
        params=state["intent"]["parameters"],
        callback=lambda progress: send_progress_to_user(progress)
    )

    state["tool_results"].append(result)
    state["final_output"] = result
    return state

def atomic_execution_node(state: AgentState) -> AgentState:
    """执行Atomic Tools组合"""
    for step in state["execution_plan"]:
        tool = get_atomic_tool(step["tool_name"])
        result = tool.execute(step["parameters"])
        state["tool_results"].append(result)

    # LLM整合结果
    state["final_output"] = synthesize_results(state["tool_results"])
    return state

def should_use_workflow(state: AgentState) -> Literal["workflow", "atomic"]:
    """路由决策"""
    return "workflow" if state["matched_workflow"] else "atomic"

# 构建状态图
workflow = StateGraph(AgentState)

# 添加节点
workflow.add_node("intent_analysis", intent_analysis_node)
workflow.add_node("workflow_matching", workflow_matching_node)
workflow.add_node("workflow_execution", workflow_execution_node)
workflow.add_node("atomic_execution", atomic_execution_node)

# 添加边(流程控制)
workflow.set_entry_point("intent_analysis")
workflow.add_edge("intent_analysis", "workflow_matching")
workflow.add_conditional_edges(
    "workflow_matching",
    should_use_workflow,
    {
        "workflow": "workflow_execution",
        "atomic": "atomic_execution"
    }
)
workflow.add_edge("workflow_execution", END)
workflow.add_edge("atomic_execution", END)

# 编译图
app = workflow.compile()
```

**关键特性**:
- ✅ 状态可序列化(支持断点续传)
- ✅ 可视化调试(导出Mermaid图)
- ✅ 支持Human-in-the-loop(用户中途调整参数)
- ✅ 异常处理(每个节点独立try-catch)

---

### 3.2 Workflow Tool实现框架

**设计目标**: 提供统一的基类,简化新Workflow Tool开发

**基类设计**:

```python
from abc import ABC, abstractmethod
from typing import Any, Callable
from enum import Enum
import time

class WorkflowStage:
    """工作流阶段定义"""
    def __init__(
        self,
        name: str,
        execute_fn: Callable,
        estimated_time: int,  # 秒
        critical: bool = True,  # 是否关键步骤
        retryable: bool = True,
        max_retries: int = 3
    ):
        self.name = name
        self.execute_fn = execute_fn
        self.estimated_time = estimated_time
        self.critical = critical
        self.retryable = retryable
        self.max_retries = max_retries

class WorkflowStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    PARTIAL_SUCCESS = "partial_success"

class BaseWorkflowTool(ABC):
    """Workflow Tool基类"""

    def __init__(self, name: str):
        self.name = name
        self.stages: list[WorkflowStage] = []
        self.current_stage_index = 0
        self.execution_log = []
        self.status = WorkflowStatus.PENDING
        self.progress_callback: Callable | None = None

    @abstractmethod
    def define_stages(self) -> list[WorkflowStage]:
        """子类实现: 定义工作流的各个阶段"""
        pass

    @abstractmethod
    def validate_params(self, params: dict) -> bool:
        """子类实现: 参数校验"""
        pass

    def execute(self, params: dict, callback: Callable | None = None) -> dict:
        """执行工作流"""
        self.progress_callback = callback

        # 1. 参数校验
        if not self.validate_params(params):
            return self._build_error_response("参数校验失败")

        # 2. 初始化阶段
        self.stages = self.define_stages()
        self.status = WorkflowStatus.RUNNING

        # 3. 逐阶段执行
        stage_results = []
        for i, stage in enumerate(self.stages):
            self.current_stage_index = i

            try:
                # 3.1 通知阶段开始
                self._notify_stage_start(stage, i)

                # 3.2 执行阶段
                start_time = time.time()
                result = self._execute_stage_with_retry(stage, params, stage_results)
                elapsed = time.time() - start_time

                # 3.3 通知阶段完成
                self._notify_stage_complete(stage, i, result, elapsed)

                # 3.4 记录结果
                stage_results.append(result)
                self._log(f"Stage {i+1}/{len(self.stages)} completed", result)

            except CriticalStageError as e:
                # 关键步骤失败,终止workflow
                self.status = WorkflowStatus.FAILED
                return self._build_error_response(str(e))

            except NonCriticalStageError as e:
                # 非关键步骤失败,降级处理
                self._notify_stage_degraded(stage, i, str(e))
                self._log(f"Stage {i+1} degraded", {"error": str(e)})
                stage_results.append(None)  # 占位

        # 4. 构建最终结果
        self.status = WorkflowStatus.COMPLETED
        return self._build_success_response(stage_results)

    def _execute_stage_with_retry(
        self,
        stage: WorkflowStage,
        params: dict,
        previous_results: list
    ) -> Any:
        """带重试机制的阶段执行"""
        last_error = None

        for attempt in range(stage.max_retries if stage.retryable else 1):
            try:
                # 执行阶段函数,传入params和前序结果
                return stage.execute_fn(params, previous_results)

            except Exception as e:
                last_error = e
                if attempt < stage.max_retries - 1:
                    self._notify_retry(stage, attempt + 1, stage.max_retries)
                    time.sleep(2 ** attempt)  # 指数退避
                else:
                    break

        # 重试耗尽
        if stage.critical:
            raise CriticalStageError(f"{stage.name} failed: {last_error}")
        else:
            raise NonCriticalStageError(f"{stage.name} failed: {last_error}")

    def _notify_stage_start(self, stage: WorkflowStage, index: int):
        """通知用户阶段开始"""
        if self.progress_callback:
            self.progress_callback({
                "type": "stage_start",
                "stage": index + 1,
                "total_stages": len(self.stages),
                "stage_name": stage.name,
                "estimated_time": stage.estimated_time
            })

    def _notify_stage_complete(self, stage: WorkflowStage, index: int, result: Any, elapsed: float):
        """通知用户阶段完成"""
        if self.progress_callback:
            self.progress_callback({
                "type": "stage_complete",
                "stage": index + 1,
                "total_stages": len(self.stages),
                "stage_name": stage.name,
                "actual_time": round(elapsed, 1),
                "result_summary": self._summarize_result(result)
            })

    def _notify_retry(self, stage: WorkflowStage, attempt: int, max_retries: int):
        """通知用户重试"""
        if self.progress_callback:
            self.progress_callback({
                "type": "retry",
                "stage_name": stage.name,
                "attempt": attempt,
                "max_retries": max_retries
            })

    def _notify_stage_degraded(self, stage: WorkflowStage, index: int, error: str):
        """通知用户阶段降级"""
        if self.progress_callback:
            self.progress_callback({
                "type": "stage_degraded",
                "stage": index + 1,
                "stage_name": stage.name,
                "error": error,
                "message": f"⚠️ {stage.name}失败,已跳过。其他功能正常"
            })

    def _log(self, message: str, data: Any = None):
        """记录执行日志"""
        self.execution_log.append({
            "timestamp": time.time(),
            "message": message,
            "data": data
        })

    def _summarize_result(self, result: Any) -> str:
        """生成结果摘要(供进度反馈)"""
        # 子类可以重写
        return str(result)[:100]

    def _build_success_response(self, stage_results: list) -> dict:
        """构建成功响应"""
        return {
            "status": "success",
            "workflow_name": self.name,
            "execution_log": self.execution_log,
            "results": stage_results
        }

    def _build_error_response(self, error_message: str) -> dict:
        """构建错误响应"""
        return {
            "status": "failed",
            "workflow_name": self.name,
            "error": error_message,
            "execution_log": self.execution_log
        }

# 自定义异常
class CriticalStageError(Exception):
    pass

class NonCriticalStageError(Exception):
    pass
```

**使用示例: UGC分析Workflow**:

```python
class UGCAnalysisWorkflow(BaseWorkflowTool):
    def __init__(self):
        super().__init__("ugc_analysis_workflow")

    def define_stages(self) -> list[WorkflowStage]:
        return [
            WorkflowStage(
                name="数据采集",
                execute_fn=self._stage_1_data_collection,
                estimated_time=240,  # 4分钟
                critical=True,  # 关键步骤
                retryable=True,
                max_retries=3
            ),
            WorkflowStage(
                name="情感分析",
                execute_fn=self._stage_2_sentiment_analysis,
                estimated_time=120,
                critical=True,
                retryable=True
            ),
            WorkflowStage(
                name="Good Case筛选",
                execute_fn=self._stage_3_good_case_selection,
                estimated_time=60,
                critical=True
            ),
            WorkflowStage(
                name="回复生成",
                execute_fn=self._stage_4_reply_generation,
                estimated_time=120,
                critical=False,  # 非关键,失败可跳过
                retryable=True
            ),
            WorkflowStage(
                name="Excel报告",
                execute_fn=self._stage_5_excel_generation,
                estimated_time=90,
                critical=True
            )
        ]

    def validate_params(self, params: dict) -> bool:
        required = ["url"]
        return all(k in params for k in required)

    def _stage_1_data_collection(self, params: dict, prev_results: list) -> dict:
        """阶段1: 调用Web抓取Atomic Tool"""
        web_scraper = get_atomic_tool("web_scraper")
        result = web_scraper.execute({
            "url": params["url"],
            "platform": params.get("platform", "auto_detect")
        })

        # 验证数据量
        if len(result["comments"]) < 10:
            raise CriticalStageError("评论数量不足10条,无法分析")

        return result

    def _stage_2_sentiment_analysis(self, params: dict, prev_results: list) -> dict:
        """阶段2: LLM直接处理情感分析"""
        comments = prev_results[0]["comments"]  # 获取阶段1结果

        # 调用LLM
        llm_result = call_llm_claude(
            prompt=f"对以下{len(comments)}条评论进行情感分析...",
            data=comments
        )

        return parse_sentiment_result(llm_result)

    # ... 其他阶段实现

    def _summarize_result(self, result: Any) -> str:
        """重写摘要方法"""
        if isinstance(result, dict) and "comments" in result:
            return f"共{len(result['comments'])}条评论"
        return super()._summarize_result(result)
```

---

### 3.3 Atomic Tools实现方案

**设计原则**: 每个Atomic Tool都是独立的,单一职责,可被Workflow Tool或Master Agent直接调用

**统一接口**:

```python
from abc import ABC, abstractmethod

class BaseAtomicTool(ABC):
    """Atomic Tool基类"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description

    @abstractmethod
    def execute(self, params: dict) -> dict:
        """执行工具,返回结果"""
        pass

    @abstractmethod
    def get_schema(self) -> dict:
        """返回工具的参数schema(用于LLM Tool Calling)"""
        pass

    def validate_params(self, params: dict) -> bool:
        """参数校验(可选,子类重写)"""
        return True
```

**具体工具实现示例**:

#### 3.3.1 Web Search Tool ⭐️新增

```python
import requests
import os
from typing import Literal

class WebSearchTool(BaseAtomicTool):
    def __init__(self):
        super().__init__(
            name="web_search",
            description="互联网搜索,返回LLM-ready结果"
        )
        self.tavily_key = os.getenv("TAVILY_API_KEY")
        self.serper_key = os.getenv("SERPER_API_KEY")

    def execute(self, params: dict) -> dict:
        query = params["query"]
        mode = params.get("mode", "ai_native")
        max_results = params.get("max_results", 5)

        if mode == "ai_native":
            return self._tavily_search(query, max_results)
        elif mode == "google_serp":
            return self._serper_search(query, max_results)

    def _tavily_search(self, query: str, max_results: int) -> dict:
        """Tavily: LLM-ready输出"""
        response = requests.post(
            "https://api.tavily.com/search",
            headers={"Authorization": f"Bearer {self.tavily_key}"},
            json={
                "query": query,
                "search_depth": "basic",
                "max_results": max_results,
                "include_answer": True,
                "include_raw_content": False
            }
        )

        data = response.json()
        return {
            "answer": data.get("answer"),
            "results": [
                {
                    "title": r["title"],
                    "url": r["url"],
                    "content": r["content"],
                    "score": r.get("score", 0)
                }
                for r in data.get("results", [])
            ],
            "source": "tavily"
        }

    def _serper_search(self, query: str, max_results: int) -> dict:
        """Serper: Google SERP"""
        response = requests.post(
            "https://google.serper.dev/search",
            headers={"X-API-KEY": self.serper_key},
            json={"q": query, "num": max_results}
        )

        data = response.json()
        return {
            "results": [
                {
                    "title": r["title"],
                    "url": r["link"],
                    "snippet": r["snippet"],
                    "position": r.get("position")
                }
                for r in data.get("organic", [])
            ],
            "source": "serper"
        }

    def get_schema(self) -> dict:
        return {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "搜索互联网,支持AI-native和Google SERP模式",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "搜索查询"},
                        "mode": {
                            "type": "string",
                            "enum": ["ai_native", "google_serp"],
                            "description": "ai_native=Tavily, google_serp=Serper"
                        },
                        "max_results": {"type": "integer", "default": 5}
                    },
                    "required": ["query"]
                }
            }
        }
```

#### 3.3.2 URL Fetch Tool ⭐️新增

```python
import requests
from firecrawl import FirecrawlApp
import os

class URLFetchTool(BaseAtomicTool):
    def __init__(self):
        super().__init__(
            name="url_fetch",
            description="从URL提取内容,支持单页/整站/AI提取"
        )
        self.firecrawl = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))

    def execute(self, params: dict) -> dict:
        url = params["url"]
        mode = params.get("mode", "simple")

        if mode == "simple":
            return self._jina_reader(url)
        elif mode == "crawl":
            return self._firecrawl_crawl(url, params)
        elif mode == "extract":
            return self._firecrawl_extract(url, params)

    def _jina_reader(self, url: str) -> dict:
        """Jina Reader: 免费、简单"""
        reader_url = f"https://r.jina.ai/{url}"
        response = requests.get(reader_url)
        return {
            "url": url,
            "markdown": response.text,
            "source": "jina_reader"
        }

    def _firecrawl_crawl(self, url: str, params: dict) -> dict:
        """Firecrawl: 整站爬取"""
        result = self.firecrawl.crawl_url(
            url,
            params={"limit": params.get("max_pages", 100)},
            wait_until_done=True
        )
        return {
            "pages": [
                {"url": p["metadata"]["sourceURL"], "markdown": p["markdown"]}
                for p in result["data"]
            ],
            "total_pages": len(result["data"])
        }

    def _firecrawl_extract(self, url: str, params: dict) -> dict:
        """Firecrawl Extract: AI提取"""
        result = self.firecrawl.extract(
            url,
            params={
                "prompt": params["extract_prompt"],
                "schema": params.get("extract_schema")
            }
        )
        return {"extracted_data": result["data"]}

    def get_schema(self) -> dict:
        return {
            "type": "function",
            "function": {
                "name": "url_fetch",
                "description": "URL内容提取",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "url": {"type": "string"},
                        "mode": {
                            "type": "string",
                            "enum": ["simple", "crawl", "extract"]
                        },
                        "max_pages": {"type": "integer"},
                        "extract_prompt": {"type": "string"},
                        "extract_schema": {"type": "object"}
                    },
                    "required": ["url"]
                }
            }
        }
```

#### 3.3.3 Web Scraper (社交平台专用)

```python
import scrapy
from playwright.sync_api import sync_playwright

class WebScraperTool(BaseAtomicTool):
    def __init__(self):
        super().__init__(
            name="web_scraper",
            description="从网页抓取数据,支持小红书/微博/抖音等平台"
        )

    def execute(self, params: dict) -> dict:
        url = params["url"]
        platform = self._detect_platform(url)

        if platform == "xiaohongshu":
            return self._scrape_xiaohongshu(url)
        elif platform == "weibo":
            return self._scrape_weibo(url)
        # ...

    def _scrape_xiaohongshu(self, url: str) -> dict:
        """使用Playwright抓取小红书(需JS渲染)"""
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()

            # 设置User-Agent和Cookie(反爬)
            page.set_extra_http_headers({
                "User-Agent": "Mozilla/5.0 ..."
            })

            page.goto(url)
            page.wait_for_selector(".comment-item", timeout=10000)

            # 滚动加载更多评论
            for _ in range(5):
                page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                page.wait_for_timeout(2000)

            # 提取评论
            comments = page.query_selector_all(".comment-item")
            results = []
            for comment in comments:
                results.append({
                    "id": comment.get_attribute("data-id"),
                    "user_name": comment.query_selector(".user-name").inner_text(),
                    "content": comment.query_selector(".content").inner_text(),
                    "likes": int(comment.query_selector(".like-count").inner_text()),
                    "timestamp": comment.query_selector(".time").inner_text()
                })

            browser.close()

            return {
                "platform": "xiaohongshu",
                "url": url,
                "comments": results,
                "total": len(results)
            }

    def get_schema(self) -> dict:
        return {
            "type": "function",
            "function": {
                "name": "web_scraper",
                "description": "从社交平台抓取内容(评论/帖子)",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "url": {
                            "type": "string",
                            "description": "要抓取的页面URL"
                        },
                        "platform": {
                            "type": "string",
                            "enum": ["xiaohongshu", "weibo", "douyin", "auto_detect"],
                            "description": "平台类型,默认自动检测"
                        }
                    },
                    "required": ["url"]
                }
            }
        }
```

#### 3.3.2 Code Executor

```python
import docker
import tempfile
import os

class CodeExecutorTool(BaseAtomicTool):
    def __init__(self):
        super().__init__(
            name="code_executor",
            description="在沙箱中执行Python代码(支持pandas/PIL/openpyxl等库)"
        )
        self.docker_client = docker.from_env()

    def execute(self, params: dict) -> dict:
        code = params["code"]
        libraries = params.get("libraries", [])
        timeout = params.get("timeout", 60)

        # 1. 创建临时目录
        with tempfile.TemporaryDirectory() as tmpdir:
            # 2. 写入代码
            code_path = os.path.join(tmpdir, "script.py")
            with open(code_path, "w") as f:
                f.write(code)

            # 3. 准备Docker容器
            container = self.docker_client.containers.run(
                image="python:3.11-slim",
                command=f"pip install {' '.join(libraries)} && python /code/script.py",
                volumes={tmpdir: {"bind": "/code", "mode": "rw"}},
                working_dir="/code",
                detach=True,
                mem_limit="512m",  # 限制内存
                cpu_period=100000,
                cpu_quota=50000,  # 限制CPU
                network_disabled=True  # 禁止网络访问(安全)
            )

            # 4. 等待执行完成
            try:
                result = container.wait(timeout=timeout)
                logs = container.logs().decode("utf-8")

                # 5. 收集生成的文件
                output_files = []
                for file in os.listdir(tmpdir):
                    if file != "script.py":
                        output_files.append(os.path.join(tmpdir, file))

                return {
                    "status": "success" if result["StatusCode"] == 0 else "failed",
                    "output": logs,
                    "files": output_files,
                    "exit_code": result["StatusCode"]
                }

            except docker.errors.ContainerError as e:
                return {
                    "status": "failed",
                    "error": str(e)
                }

            finally:
                container.remove(force=True)

    def get_schema(self) -> dict:
        return {
            "type": "function",
            "function": {
                "name": "code_executor",
                "description": "执行Python代码生成文件(Excel/图片等)",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "code": {
                            "type": "string",
                            "description": "要执行的Python代码"
                        },
                        "libraries": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "需要安装的Python库",
                            "example": ["openpyxl", "pandas", "matplotlib"]
                        },
                        "timeout": {
                            "type": "integer",
                            "description": "超时时间(秒),默认60"
                        }
                    },
                    "required": ["code"]
                }
            }
        }
```

#### 3.3.3 Vision Service

```python
from transformers import CLIPProcessor, CLIPModel
import torch
from PIL import Image
import requests

class VisionServiceTool(BaseAtomicTool):
    def __init__(self):
        super().__init__(
            name="vision_service",
            description="图像理解(风格分析/元素识别/文字提取)"
        )
        # 加载CLIP模型
        self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

    def execute(self, params: dict) -> dict:
        image_url = params["image_url"]
        tasks = params.get("tasks", ["style_analysis"])

        # 下载图片
        image = Image.open(requests.get(image_url, stream=True).raw)

        results = {}

        if "style_analysis" in tasks:
            results["style"] = self._analyze_style(image)

        if "color_palette" in tasks:
            results["colors"] = self._extract_colors(image)

        # ... 其他任务

        return results

    def _analyze_style(self, image: Image) -> dict:
        """使用CLIP进行风格分类"""
        style_labels = [
            "扁平化设计", "拟物化设计", "渐变风格",
            "极简主义", "复古风格", "赛博朋克"
        ]

        inputs = self.processor(
            text=style_labels,
            images=image,
            return_tensors="pt",
            padding=True
        )

        outputs = self.model(**inputs)
        logits_per_image = outputs.logits_per_image
        probs = logits_per_image.softmax(dim=1)

        # 返回Top 3风格
        top_3 = torch.topk(probs, 3)
        return {
            style_labels[idx]: float(prob)
            for idx, prob in zip(top_3.indices[0], top_3.values[0])
        }

    def _extract_colors(self, image: Image) -> list:
        """提取主色调"""
        # 简化版:使用k-means聚类
        from sklearn.cluster import KMeans
        import numpy as np

        # 缩小图片加速
        image = image.resize((100, 100))
        pixels = np.array(image).reshape(-1, 3)

        # 聚类找5个主色
        kmeans = KMeans(n_clusters=5, random_state=0).fit(pixels)
        colors = kmeans.cluster_centers_.astype(int)

        return [
            {"r": int(c[0]), "g": int(c[1]), "b": int(c[2])}
            for c in colors
        ]

    def get_schema(self) -> dict:
        return {
            "type": "function",
            "function": {
                "name": "vision_service",
                "description": "图像理解和分析",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "image_url": {
                            "type": "string",
                            "description": "图片URL"
                        },
                        "tasks": {
                            "type": "array",
                            "items": {
                                "type": "string",
                                "enum": ["style_analysis", "color_palette", "ocr", "object_detection"]
                            },
                            "description": "要执行的任务列表"
                        }
                    },
                    "required": ["image_url"]
                }
            }
        }
```

---

## 4. 部署方案

### 4.1 MVP部署架构(单机版)

```
┌────────────────────────────────────────────┐
│         Docker Compose 一键部署             │
├────────────────────────────────────────────┤
│                                            │
│  ┌──────────────┐  ┌──────────────┐       │
│  │ CreativeFlow │  │ PostgreSQL   │       │
│  │ App          │  │              │       │
│  │ (Gradio UI)  │  │              │       │
│  └──────────────┘  └──────────────┘       │
│                                            │
│  ┌──────────────┐  ┌──────────────┐       │
│  │ Redis        │  │ MinIO        │       │
│  │ (缓存)       │  │ (文件存储)   │       │
│  └──────────────┘  └──────────────┘       │
│                                            │
└────────────────────────────────────────────┘
```

**docker-compose.yml**:

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "7860:7860"  # Gradio端口
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/creativeflow
      - REDIS_URL=redis://redis:6379
      - MINIO_ENDPOINT=minio:9000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    depends_on:
      - postgres
      - redis
      - minio
    volumes:
      - ./data:/app/data

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: creativeflow
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data

volumes:
  postgres_data:
  minio_data:
```

### 4.2 生产部署架构(云原生)

```
┌─────────────────────────────────────────────────────────┐
│                    Kubernetes集群                        │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌──────────────────────────────────────────────────┐  │
│  │              Ingress (负载均衡)                   │  │
│  └──────────────────┬───────────────────────────────┘  │
│                     │                                   │
│         ┌───────────┼───────────┐                      │
│         │           │           │                       │
│         ▼           ▼           ▼                       │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐               │
│  │ Master   │ │ Master   │ │ Master   │  (横向扩展)   │
│  │ Agent    │ │ Agent    │ │ Agent    │               │
│  │ Pod 1    │ │ Pod 2    │ │ Pod 3    │               │
│  └──────────┘ └──────────┘ └──────────┘               │
│         │           │           │                       │
│         └───────────┼───────────┘                      │
│                     │                                   │
│  ┌─────────────────┴────────────────────────┐         │
│  │          Worker Nodes (Celery)           │         │
│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐    │         │
│  │  │Worker 1 │ │Worker 2 │ │Worker 3 │    │         │
│  │  │(Workflow│ │(Web     │ │(Vision  │    │  (按需) │
│  │  │ Tools)  │ │ Scraper)│ │ Service)│    │  扩展   │
│  │  └─────────┘ └─────────┘ └─────────┘    │         │
│  └──────────────────────────────────────────┘         │
│                                                         │
└─────────────────────────────────────────────────────────┘
            │                   │
            ▼                   ▼
    ┌──────────────┐    ┌──────────────┐
    │ Cloud RDS    │    │ S3 / OSS     │
    │ (PostgreSQL) │    │ (对象存储)   │
    └──────────────┘    └──────────────┘
```

---

## 5. 开发路线图

### Phase 1: MVP (4周)

**目标**: 验证核心架构,完成封面生成场景

**交付物**:
- ✅ Master Agent基础框架(LangGraph)
- ✅ 1个Atomic Tool: Vision Service(图像风格分析)
- ✅ LLM直接生成文字图(PIL代码生成 + 代码执行)
- ✅ Gradio UI原型
- ✅ Docker Compose一键部署

**工作量**: 约80小时
- Week 1: LangGraph架构搭建 + 意图识别
- Week 2: Vision Service开发 + 模型部署
- Week 3: 代码生成与执行沙箱
- Week 4: Gradio UI + 端到端调试

---

### Phase 2: V1.5 运营场景 (3周)

**目标**: 引入Workflow Tool,支持UGC分析场景

**交付物**:
- ✅ Workflow Tool基类框架
- ✅ UGC分析Workflow(完整5步流程)
- ✅ Web Scraper Atomic Tool(小红书/微博)
- ✅ 进度反馈机制
- ✅ 异常处理与重试

**工作量**: 约60小时
- Week 1: Workflow基类 + 进度反馈
- Week 2: Web Scraper(Playwright反爬)
- Week 3: UGC分析端到端测试

---

### Phase 3: V2.0 完善工具矩阵 (4周)

**目标**: 扩展到更多场景和平台

**交付物**:
- ✅ 活动策划Workflow
- ✅ 数据报告Workflow
- ✅ 更多Atomic Tools(图库搜索、文档生成等)
- ✅ 监控告警系统
- ✅ 生产部署文档

---

## 6. MVP最终技术决策

### 6.1 核心决策确认

1. ✅ **状态管理方案**: 自研轻量级状态机（~200行代码）
   - 理由: MVP状态流转简单（意图识别 → Workflow匹配 → 执行），LangGraph过重

2. ✅ **MVP场景范围**:
   - 场景1: UGC分析工作流（运营场景）
   - 场景2: 封面生成工作流（创作场景）

3. ✅ **LLM调用策略**:
   - Web UI提供模型选择下拉框，用户自主选择
   - 默认模型: `ernie-5.0-thinking-preview` (EB5端点)
   - 可选模型: `glm-4.5`, `gpt-5`, `doubao-seed-1-6-thinking-250615`, `gemini-2.5-pro`

4. ✅ **代码执行沙箱**:
   - MVP阶段: subprocess隔离（限制超时30s、内存512MB）
   - V1.5阶段: 引入Docker容器隔离

5. ✅ **数据存储**:
   - MVP阶段: 无数据库，使用Gradio内置会话 + 本地文件系统
   - V1.5阶段: 按需引入SQLite/Redis

### 6.2 MVP简化架构

```
┌─────────────────────────────────────┐
│      Gradio Web UI (会话管理)        │
│   • 模型选择器（默认EB5）             │
│   • 对话交互                         │
│   • 文件上传/下载                    │
└──────────────┬──────────────────────┘
               │
               ↓
┌─────────────────────────────────────┐
│    Master Agent (自研状态机)         │
│   • 意图识别                         │
│   • Workflow匹配与调度               │
└──────────────┬──────────────────────┘
               │
      ┌────────┴────────┐
      ↓                 ↓
┌──────────┐      ┌──────────┐
│ Workflow │      │ Atomic   │
│  Tools   │      │  Tools   │
├──────────┤      ├──────────┤
│UGC分析   │      │Web搜索   │
│封面生成  │      │URL抓取   │
└──────────┘      │代码执行  │
                  └──────────┘
                       │
                       ↓
              ┌─────────────────┐
              │  External APIs  │
              │ Tavily/Serper   │
              │ Jina/Firecrawl  │
              └─────────────────┘
                       │
                       ↓
              ┌─────────────────┐
              │  本地文件系统    │
              │  /outputs/      │
              └─────────────────┘
```

### 6.3 开发路线图更新

**Week 1: 基础设施**
- 创建项目目录结构
- Config配置管理（加载.env）
- LLMClient统一接口（支持多模型切换）
- Logger工具类

**Week 2: Atomic Tools**
- BaseAtomicTool抽象基类
- WebSearchTool（Tavily主 + Serper备）
- URLFetchTool（Jina主 + Firecrawl备）
- CodeExecutor（subprocess隔离）

**Week 3: Workflow Tools**
- BaseWorkflowTool抽象基类
- UGCAnalysisWorkflow（5步流程）
- 封面生成Workflow（3步流程）

**Week 4: Master Agent + UI**
- 自研状态机
- MasterAgent核心逻辑（意图识别 + 调度）
- Gradio UI（含模型选择器）
- 端到端测试

---

## 7. 立即开始实施

**当前状态**: ✅ 所有技术决策已明确，开始编码

**第一个PR目标**: 完成基础设施层（Config + LLMClient + Logger）

---

以上就是CreativeFlow的完整技术方案设计,涵盖了架构、技术栈、核心模块实现、部署方案和开发路线图。
