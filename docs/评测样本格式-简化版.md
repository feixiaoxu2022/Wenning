# CreativeFlow 评测样本格式 - 简化版

## 核心思想

**最简化原则**：一个样本文件 = 任务描述 + 评测检查项

不搞复杂的分层、模板、配置分离。**所有信息都在一个JSON文件里**。

---

## 样本格式定义

### 基础结构

```json
{
  "data_id": "EVAL_001",
  "task_name": "技术文章配图生成",
  "query": "为一篇关于\"Python异步编程\"的技术博客生成5张配图:\n\n1. async_concept.png - 同步vs异步概念对比图\n2. async_flow.png - asyncio事件循环流程图\n3. async_performance.png - 性能对比柱状图\n4. async_architecture.png - 协程架构示意图\n5. async_summary.png - 知识点总结卡片\n\n要求:\n- 所有图片尺寸1200x800\n- 使用蓝色系配色\n- 文字清晰易读",

  "models": {
    "model_a": "gpt-4",
    "model_b": "claude-3.5-sonnet"
  },

  "expected_outputs": [
    "async_concept.png",
    "async_flow.png",
    "async_performance.png",
    "async_architecture.png",
    "async_summary.png"
  ],

  "timeout": 150,

  "check_list": [
    {
      "check_type": "file_count_equals",
      "params": {
        "expected": 5
      },
      "weight": 1.0,
      "description": "检查是否生成了5个文件"
    },
    {
      "check_type": "file_format_check",
      "params": {
        "expected_formats": ["png"]
      },
      "weight": 1.0,
      "description": "检查文件格式是否为PNG"
    },
    {
      "check_type": "image_size_check",
      "params": {
        "width": 1200,
        "height": 800,
        "tolerance": 0.1
      },
      "weight": 0.5,
      "description": "检查图片尺寸是否符合要求"
    },
    {
      "check_type": "llm_judge",
      "params": {
        "judge_model": "gpt-4",
        "prompt": "请评估这些图片的整体质量(1-5分):\n- 配色是否为蓝色系\n- 文字是否清晰\n- 内容是否符合要求\n\n评分:\n理由:",
        "score_range": [1, 5],
        "temperature": 0.3
      },
      "weight": 2.0,
      "description": "LLM评估图片质量"
    },
    {
      "check_type": "human_annotation",
      "params": {
        "dimensions": ["professionalism", "creativity", "usability"],
        "options": ["model_a", "model_b", "tie"],
        "question": "整体质量对比，哪个更好？"
      },
      "weight": 3.0,
      "description": "人工标注整体质量"
    }
  ],

  "meta": {
    "difficulty": 4,
    "tags": ["image_generation", "technical"],
    "created_at": "2025-01-15T10:00:00Z",
    "eval_config": {
      "enable_position_randomization": true,
      "enable_llm_judge_cache": true,
      "require_human_annotation": true
    }
  }
}
```

### 字段说明

#### 核心字段
- `data_id`: 样本唯一标识符
- `task_name`: 任务名称
- `query`: 发送给Agent的任务描述（prompt）
- `models`: 对比的两个模型
  - `model_a`: 模型A的ID（如 "gpt-4"）
  - `model_b`: 模型B的ID（如 "claude-3.5-sonnet"）
- **`expected_outputs`**: 预期生成的文件列表（用于文件匹配检查）
- `timeout`: 任务执行超时时间（秒）

#### check_list字段
每个检查项包含：
- `check_type`: 检查类型（rule-based / llm_judge / human_annotation）
- `params`: 检查参数（根据check_type不同而不同）
- `weight`: 权重（用于计算最终得分）
- `description`: 检查项说明

#### meta字段
- `difficulty`: 任务难度（1-5）
- `tags`: 任务标签
- `created_at`: 创建时间
- **`eval_config`**: 评测控制配置
  - `enable_position_randomization`: 是否启用位置随机化（避免LLM Judge位置偏见）
  - `enable_llm_judge_cache`: 是否启用LLM Judge结果缓存
  - `require_human_annotation`: 是否必需人工标注

---

## 检查项类型 (check_type)

### 1. Rule-based 检查

#### `file_count_equals`
```json
{
  "check_type": "file_count_equals",
  "params": {"expected": 5},
  "weight": 1.0,
  "description": "检查文件数量"
}
```

#### `file_format_check`
```json
{
  "check_type": "file_format_check",
  "params": {"expected_formats": ["png", "jpg"]},
  "weight": 1.0,
  "description": "检查文件格式"
}
```

#### `image_size_check`
```json
{
  "check_type": "image_size_check",
  "params": {
    "width": 1200,
    "height": 800,
    "tolerance": 0.1
  },
  "weight": 0.5,
  "description": "检查图片尺寸"
}
```

#### `excel_sheets_check`
```json
{
  "check_type": "excel_sheets_check",
  "params": {
    "expected_sheets": ["定价对比", "功能矩阵", "时间线"]
  },
  "weight": 1.0,
  "description": "检查Excel是否包含预期的sheet"
}
```

#### `file_size_check`
```json
{
  "check_type": "file_size_check",
  "params": {
    "min_size_kb": 10,
    "max_size_mb": 50
  },
  "weight": 0.5,
  "description": "检查文件大小是否合理"
}
```

### 2. LLM Judge 检查

```json
{
  "check_type": "llm_judge",
  "params": {
    "judge_model": "gpt-4",
    "prompt": "评估图片质量...",
    "score_range": [1, 5],
    "temperature": 0.3
  },
  "weight": 2.0,
  "description": "LLM评估质量"
}
```

### 3. Human Annotation

```json
{
  "check_type": "human_annotation",
  "params": {
    "dimensions": ["professionalism", "creativity", "usability"],
    "options": ["model_a", "model_b", "tie"],
    "question": "哪个模型的输出更好？"
  },
  "weight": 3.0,
  "description": "人工标注"
}
```

**参数说明**：
- `dimensions`: 评估维度列表
- **`options`**: 标注选项（必需），通常为 `["model_a", "model_b", "tie"]`
- `question`: 标注问题描述

---

## 完整示例

### 示例1: 图片生成任务

```json
{
  "data_id": "EVAL_ASYNC_IMG_001",
  "task_name": "Python异步编程配图生成",
  "query": "为一篇关于\"Python异步编程\"的技术博客生成5张配图:\n\n1. async_concept.png - 同步vs异步概念对比图(用简单图形对比两种模式)\n2. async_flow.png - asyncio事件循环流程图(展示事件循环的工作原理)\n3. async_performance.png - 性能对比柱状图(模拟数据:同步耗时10s,异步耗时2s)\n4. async_architecture.png - 协程架构示意图(展示协程、任务、事件循环的关系)\n5. async_summary.png - 知识点总结卡片(列出3-5个核心要点)\n\n要求:\n- 所有图片尺寸1200x800\n- 使用专业的配色方案(蓝色系为主)\n- 文字清晰易读\n- 风格统一",

  "models": {
    "model_a": "gpt-4",
    "model_b": "claude-3.5-sonnet"
  },

  "expected_outputs": [
    "async_concept.png",
    "async_flow.png",
    "async_performance.png",
    "async_architecture.png",
    "async_summary.png"
  ],

  "timeout": 150,

  "check_list": [
    {
      "check_type": "file_count_equals",
      "params": {"expected": 5},
      "weight": 1.0,
      "description": "生成5个文件"
    },
    {
      "check_type": "file_format_check",
      "params": {"expected_formats": ["png"]},
      "weight": 1.0,
      "description": "文件格式为PNG"
    },
    {
      "check_type": "image_size_check",
      "params": {"width": 1200, "height": 800, "tolerance": 0.1},
      "weight": 0.5,
      "description": "图片尺寸1200x800"
    },
    {
      "check_type": "llm_judge",
      "params": {
        "judge_model": "gpt-4",
        "prompt": "请评估async_concept.png是否准确展示了\"同步vs异步\"的概念对比。\n\n评分标准(1-5分):\n5分: 概念清晰准确，对比明显\n3分: 基本正确但表达不够清晰\n1分: 概念错误或无关\n\n评分:\n理由:",
        "score_range": [1, 5]
      },
      "weight": 2.0,
      "description": "概念准确性"
    },
    {
      "check_type": "llm_judge",
      "params": {
        "judge_model": "gpt-4",
        "prompt": "请评估所有图片的整体专业性(1-5分):\n- 布局设计是否合理\n- 配色是否专业(蓝色系)\n- 信息层次是否清晰\n\n评分:\n理由:",
        "score_range": [1, 5]
      },
      "weight": 1.5,
      "description": "整体专业性"
    },
    {
      "check_type": "human_annotation",
      "params": {
        "dimensions": ["professionalism", "creativity", "usability", "wow_factor"],
        "question": "整体质量对比，哪个模型更好？"
      },
      "weight": 3.0,
      "description": "人工标注"
    }
  ],

  "meta": {
    "difficulty": 4,
    "tags": ["image_generation", "technical", "visualization"],
    "created_at": "2025-01-15T10:00:00Z",
    "created_by": "system"
  }
}
```

### 示例2: 数据分析任务

```json
{
  "data_id": "EVAL_COMPETITOR_ANALYSIS_001",
  "task_name": "AI行业竞品分析",
  "query": "搜索2025年AI Agent领域的主要竞品(Claude、GPT、Gemini、文心一言),收集以下信息并生成分析报告:\n\n1. 定价对比(免费额度、付费套餐价格)\n2. 核心功能特性对比\n3. 主要发布时间线\n\n要求:\n- 生成Excel文件 ai_competitors_analysis.xlsx,包含多个sheet:定价对比、功能矩阵、时间线\n- 生成交互式HTML对比页面 ai_dashboard.html,包含表格和简单图表\n- 数据要真实准确,来自2024-2025年的最新信息",

  "models": {
    "model_a": "gpt-4",
    "model_b": "claude-3.5-sonnet"
  },

  "timeout": 180,

  "check_list": [
    {
      "check_type": "file_count_equals",
      "params": {"expected": 2},
      "weight": 1.0,
      "description": "生成2个文件(Excel和HTML)"
    },
    {
      "check_type": "excel_sheets_check",
      "params": {
        "expected_sheets": ["定价对比", "功能矩阵", "时间线"]
      },
      "weight": 1.0,
      "description": "Excel包含3个sheet"
    },
    {
      "check_type": "llm_judge",
      "params": {
        "judge_model": "gpt-4",
        "prompt": "请评估Excel中的数据是否准确和完整(1-5分):\n- 定价信息是否真实\n- 功能对比是否全面\n- 时间线是否准确\n\n评分:\n理由:",
        "score_range": [1, 5]
      },
      "weight": 2.0,
      "description": "数据准确性"
    },
    {
      "check_type": "llm_judge",
      "params": {
        "judge_model": "gpt-4",
        "prompt": "请评估HTML页面的质量(1-5分):\n- 表格展示是否清晰\n- 是否包含图表\n- 是否具有交互性\n\n评分:\n理由:",
        "score_range": [1, 5]
      },
      "weight": 1.5,
      "description": "HTML页面质量"
    },
    {
      "check_type": "human_annotation",
      "params": {
        "dimensions": ["completeness", "accuracy", "usability"],
        "options": ["model_a", "model_b", "tie"],
        "question": "整体分析报告质量，哪个更好？"
      },
      "weight": 3.0,
      "description": "人工标注"
    }
  ],

  "meta": {
    "difficulty": 4,
    "tags": ["data_analysis", "research", "excel"],
    "created_at": "2025-01-15T11:00:00Z",
    "eval_config": {
      "enable_position_randomization": true,
      "enable_llm_judge_cache": true,
      "require_human_annotation": true
    }
  }
}
```

---

## 评测结果格式

```json
{
  "result_id": "RESULT_20250115_001",
  "sample_id": "EVAL_ASYNC_IMG_001",
  "evaluated_at": "2025-01-15T12:00:00Z",
  "evaluated_by": "user_alice",

  "executions": {
    "model_a": {
      "model_name": "gpt-4",
      "status": "success",
      "duration_seconds": 45.2,
      "generated_files": ["async_concept.png", "async_flow.png", "async_performance.png", "async_architecture.png", "async_summary.png"],
      "output_dir": "outputs/conv_abc123",
      "conversation_id": "conv_abc123",
      "token_usage": 15234
    },
    "model_b": {
      "model_name": "claude-3.5-sonnet",
      "status": "success",
      "duration_seconds": 38.7,
      "generated_files": ["async_concept.png", "async_flow.png", "async_performance.png", "async_architecture.png", "async_summary.png"],
      "output_dir": "outputs/conv_def456",
      "conversation_id": "conv_def456",
      "token_usage": 12890
    }
  },

  "check_results": {
    "model_a": [
      {
        "check_type": "file_count_equals",
        "score": 1.0,
        "passed": true,
        "details": "生成 5/5 个文件",
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      },
      {
        "check_type": "image_size_check",
        "score": 1.0,
        "passed": true,
        "details": "5/5 张图片尺寸符合",
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      },
      {
        "check_type": "llm_judge",
        "score": 0.8,
        "passed": true,
        "details": "4/5分 - 概念对比清晰，但文字略小",
        "raw_data": {
          "llm_response": "分数: 4\n理由: 概念对比清晰，但文字略小",
          "judge_model": "gpt-4",
          "judge_tokens": 234
        },
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      }
    ],
    "model_b": [
      {
        "check_type": "file_count_equals",
        "score": 1.0,
        "passed": true,
        "details": "生成 5/5 个文件",
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      },
      {
        "check_type": "image_size_check",
        "score": 0.8,
        "passed": false,
        "details": "4/5 张图片尺寸符合\n不符合项: async_flow.png: 1100x800",
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      },
      {
        "check_type": "llm_judge",
        "score": 1.0,
        "passed": true,
        "details": "5/5分 - 完美展示同步异步差异，图文并茂",
        "raw_data": {
          "llm_response": "分数: 5\n理由: 完美展示同步异步差异，图文并茂",
          "judge_model": "gpt-4",
          "judge_tokens": 198
        },
        "human_override": false,
        "human_corrected_score": null,
        "correction_reason": null,
        "corrected_by": null,
        "corrected_at": null
      }
    ]
  },

  "human_annotation": {
    "dimensions": {
      "professionalism": "model_b",
      "creativity": "model_a",
      "usability": "model_b"
    },
    "overall_preference": "model_b",
    "notes": "Model B整体更专业可用，虽然A在创意上有亮点但B的视觉呈现更清晰",
    "annotated_by": "user_alice",
    "annotated_at": "2025-01-15T12:15:00Z",
    "time_spent_seconds": 320
  },

  "scores": {
    "model_a": {
      "final_score": 0.85,
      "breakdown": {
        "rule_based_score": 1.0,
        "llm_judge_score": 0.8,
        "human_score": 0.625
      }
    },
    "model_b": {
      "final_score": 0.92,
      "breakdown": {
        "rule_based_score": 0.9,
        "llm_judge_score": 1.0,
        "human_score": 0.75
      }
    }
  },

  "comparison": {
    "winner": "model_b",
    "score_diff": 0.07,
    "key_differences": [
      "Model B在LLM Judge评测中表现更好（1.0 vs 0.8）",
      "Model A在图片尺寸方面更准确（1.0 vs 0.8）",
      "人工标注倾向于Model B（0.75 vs 0.625）"
    ]
  }
}
```

### 结果字段说明

#### check_results中的关键字段
每个检查结果包含：
- `check_type`: 检查类型
- `score`: 得分（0.0-1.0）
- `passed`: 是否通过
- `details`: 详细说明
- **`human_override`**: 是否被人工修正
- **`human_corrected_score`**: 人工修正后的分数
- **`correction_reason`**: 修正理由
- **`corrected_by`**: 修正人
- **`corrected_at`**: 修正时间
- `raw_data`: 原始数据（如LLM Judge的完整响应）

#### human_annotation字段
- `dimensions`: 各维度的标注结果（如 `{"professionalism": "model_b"}`）
- `overall_preference`: 综合偏好
- `notes`: 标注备注
- `annotated_by`: 标注人
- `annotated_at`: 标注时间
- **`time_spent_seconds`**: 标注耗时（秒）

#### comparison字段
自动生成的对比总结：
- `winner`: 获胜方
- `score_diff`: 分数差距
- `key_differences`: 关键差异点列表

---

## 工具实现

### 后端API

```python
@app.post("/api/evaluation/run")
async def run_evaluation(sample_file: str):
    """运行评测"""
    # 1. 加载样本
    with open(sample_file) as f:
        sample = json.load(f)

    # 2. 执行两个模型
    exec_a = await execute_model(sample['models']['model_a'], sample['query'])
    exec_b = await execute_model(sample['models']['model_b'], sample['query'])

    # 3. 运行检查项
    results_a = []
    results_b = []

    for check in sample['check_list']:
        if check['check_type'] in RULE_CHECKS:
            # Rule-based检查
            results_a.append(run_rule_check(check, exec_a))
            results_b.append(run_rule_check(check, exec_b))
        elif check['check_type'] == 'llm_judge':
            # LLM Judge
            results_a.append(await run_llm_judge(check, exec_a))
            results_b.append(await run_llm_judge(check, exec_b))

    # 4. 保存结果
    result = {
        "result_id": generate_id(),
        "sample_id": sample['data_id'],
        "executions": {"model_a": exec_a, "model_b": exec_b},
        "check_results": {"model_a": results_a, "model_b": results_b}
    }

    save_result(result)
    return result
```

### 检查器实现

```python
RULE_CHECKS = {
    "file_count_equals": lambda params, exec: check_file_count(exec, params['expected']),
    "file_format_check": lambda params, exec: check_file_format(exec, params['expected_formats']),
    "image_size_check": lambda params, exec: check_image_size(exec, params),
    "excel_sheets_check": lambda params, exec: check_excel_sheets(exec, params['expected_sheets']),
}

def run_rule_check(check, execution):
    checker = RULE_CHECKS[check['check_type']]
    result = checker(check['params'], execution)
    return {
        "check_type": check['check_type'],
        "score": result['score'],
        "passed": result['passed'],
        "details": result['details']
    }
```

---

## 批量生成脚本

```python
# scripts/generate_samples.py

TASKS = [
    {
        "data_id": "EVAL_ASYNC_IMG",
        "task_name": "异步编程配图",
        "query": "...",
        "check_list": [...]
    },
    # 更多任务...
]

MODELS = [
    ("gpt-4", "claude-3.5-sonnet"),
    ("gpt-4", "gemini-pro"),
    ("claude-3.5-sonnet", "gemini-pro"),
]

for task in TASKS:
    for model_a, model_b in MODELS:
        sample = {
            "data_id": f"{task['data_id']}_{model_a}_vs_{model_b}",
            "task_name": task['task_name'],
            "query": task['query'],
            "models": {"model_a": model_a, "model_b": model_b},
            "check_list": task['check_list'],
            "timeout": 150,
            "meta": {"created_at": datetime.now().isoformat()}
        }

        with open(f"samples/{sample['data_id']}.json", 'w') as f:
            json.dump(sample, f, ensure_ascii=False, indent=2)
```

---

## 总结

### 这个简化格式的优势

✅ **极简** - 一个JSON文件包含所有信息
✅ **直观** - 格式类似你现有的bikeshare样本
✅ **易扩展** - 需要新检查项？直接加到check_list
✅ **易维护** - 不需要理解复杂的分层结构
✅ **工程化** - 支持批量生成、版本控制

### 与原复杂方案对比

| 特性 | 复杂版 | 简化版 |
|------|--------|--------|
| 文件数量 | 3层(任务/配置/样本) | 1个JSON |
| 学习成本 | 高 | 低 |
| 灵活性 | 高 | 中 |
| 适用场景 | 大规模benchmark | 快速迭代 |

---

**使用建议**：先用简化版快速上手，如果后续需要更复杂的配置管理，再考虑分层设计。
